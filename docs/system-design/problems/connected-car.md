# Design a Connected Car Platform (Tesla, GM OnStar)

A scalable IoT platform that enables over-the-air (OTA) software updates, real-time vehicle telemetry collection, remote control capabilities, fleet management, and predictive maintenance for connected vehicles at global scale.

**Difficulty:** üî¥ Hard | **Frequency:** ‚≠ê‚≠ê‚≠ê‚≠ê High | **Time:** 60-75 minutes

---

## Quick Overview

| Aspect | Details |
|--------|---------|
| **Scale** | 10M vehicles, 1B telemetry events/day, 50M remote commands/day, 10K OTA updates/day |
| **Key Challenges** | OTA update delivery with rollback, CAN bus data parsing, cellular/satellite communication, delta patching, edge computing in vehicle, predictive maintenance ML |
| **Core Concepts** | Vehicle gateway ECU, telemetry ingestion pipeline, OTA delta updates, remote command execution, time-series analytics, edge processing, firmware versioning |
| **Companies** | Tesla, GM OnStar, BMW ConnectedDrive, Mercedes-Benz User Experience (MBUX), Ford Sync, Rivian, Lucid Motors |

---

=== "üìã Step 1: Requirements"

    ## Functional Requirements

    **Core Features:**

    | Feature | Description | Priority |
    |---------|-------------|----------|
    | **OTA Updates** | Deploy software updates wirelessly to vehicles | P0 (Must have) |
    | **Telemetry Collection** | Collect real-time vehicle data (speed, battery, diagnostics) | P0 (Must have) |
    | **Remote Control** | Lock/unlock, climate control, horn/lights | P0 (Must have) |
    | **Fleet Management** | Monitor vehicle health, location, utilization | P0 (Must have) |
    | **Predictive Maintenance** | ML-based failure prediction and alerts | P0 (Must have) |
    | **Real-time Diagnostics** | Detect and report faults (DTC codes) | P0 (Must have) |
    | **Remote Diagnostics** | Cloud-based troubleshooting and support | P1 (Should have) |
    | **Geofencing** | Location-based alerts and restrictions | P1 (Should have) |
    | **Trip Analytics** | Driving behavior, efficiency metrics | P1 (Should have) |
    | **Voice Commands** | Natural language vehicle control | P2 (Nice to have) |
    | **App Ecosystem** | Third-party app deployment to vehicles | P2 (Nice to have) |
    | **Vehicle Sharing** | Temporary access for other users | P2 (Nice to have) |

    **Explicitly Out of Scope** (mention in interview):

    - Autonomous driving software stack
    - In-vehicle entertainment content (music/video streaming)
    - Navigation map updates (assume separate system)
    - Manufacturing and supply chain management
    - Insurance telematics and pricing
    - Charging station network management

    ---

    ## Non-Functional Requirements

    | Requirement | Target | Reasoning |
    |-------------|--------|-----------|
    | **Availability** | 99.99% uptime (cloud), 99.5% (vehicle connectivity) | Critical for safety features, remote assistance |
    | **Latency (Remote Commands)** | < 2s command execution | User expects instant response for lock/unlock |
    | **Latency (Telemetry)** | < 5s end-to-end | Real-time monitoring for critical events |
    | **OTA Reliability** | 99.9% success rate | Failed updates can brick vehicles |
    | **Bandwidth Efficiency** | < 50 MB/day/vehicle avg | Cellular data cost optimization |
    | **Security** | Zero-trust, E2E encryption | Prevent vehicle theft, privacy protection |
    | **Compliance** | GDPR, CCPA, ISO 26262 (automotive safety) | Legal requirements, safety standards |
    | **Scalability** | 100M vehicles in 5 years | Support rapid fleet growth |
    | **Data Retention** | 7 years telemetry | Regulatory compliance, warranty claims |

    ---

    ## Capacity Estimation

    ### Traffic Estimates

    ```
    Vehicles & Users:
    - Total vehicles: 10M connected vehicles
    - Active vehicles per day: 7M (70% drive daily)
    - Average users per vehicle: 1.5 (family/shared)
    - Total users: 15M users

    Telemetry events:
    - High-frequency sensors: 1 Hz (battery, speed, GPS)
    - Medium-frequency: 0.1 Hz (tire pressure, temperatures)
    - Low-frequency: 0.01 Hz (odometer, service data)
    - Average events per vehicle: 100/minute = 6,000/hour
    - Total events per day: 10M √ó 6,000 √ó 24 = 1.44B events/day
    - Telemetry QPS: 1.44B / 86,400 = ~16,700 events/sec
    - Peak QPS (commute hours): 5x = ~83,500 events/sec

    Remote commands:
    - Commands per vehicle/day: 5 (lock, unlock, climate, etc.)
    - Total commands/day: 7M √ó 5 = 35M commands/day
    - Command QPS: 35M / 86,400 = ~405 commands/sec
    - Peak QPS: 2,000 commands/sec

    OTA updates:
    - Update campaigns: 20/year
    - Vehicles per campaign: 500K average
    - Campaign duration: 30 days
    - Daily update deliveries: 500K / 30 = 16.7K updates/day
    - Concurrent downloads: ~500 vehicles
    - Peak concurrent: 2,000 vehicles

    Fleet queries (dashboard):
    - Fleet managers: 10K (commercial fleets)
    - Queries per manager/day: 50
    - Total queries/day: 500K queries/day
    - Query QPS: 500K / 86,400 = ~6 queries/sec

    Vehicle location updates:
    - GPS updates: 1/minute when driving
    - Active vehicles: 7M
    - Average drive time: 1 hour/day
    - Location updates: 7M √ó 60 = 420M/day
    - Location QPS: 420M / 86,400 = ~4,860/sec
    ```

    ### Storage Estimates

    ```
    Telemetry data (time-series):
    - Events per day: 1.44B events
    - Average event size: 150 bytes (sensor_id, timestamp, value, metadata)
    - Daily: 1.44B √ó 150 bytes = 216 GB/day
    - Monthly: 216 GB √ó 30 = 6.48 TB/month
    - Yearly: 6.48 TB √ó 12 = 77.76 TB/year
    - 7-year retention: 77.76 TB √ó 7 = 544 TB
    - With compression (5:1): 109 TB

    Vehicle metadata:
    - Total vehicles: 10M
    - Vehicle record: 10 KB (VIN, model, features, config, owner)
    - 10M √ó 10 KB = 100 GB

    Software versions & OTA packages:
    - ECU modules per vehicle: 50 (infotainment, battery, autopilot, etc.)
    - Versions per module: 20 historical
    - Package size: 500 MB average (full), 50 MB (delta)
    - Total packages: 50 modules √ó 20 versions = 1,000 packages
    - Storage: 1,000 √ó 500 MB = 500 GB (full), 50 GB (deltas)
    - Deployment metadata: 100 GB

    Diagnostic trouble codes (DTCs):
    - DTC events: 10M vehicles √ó 2 DTCs/month = 20M/month
    - DTC record: 500 bytes (code, timestamp, context, resolution)
    - Monthly: 20M √ó 500 bytes = 10 GB/month
    - Yearly: 10 GB √ó 12 = 120 GB/year
    - 7-year retention: 840 GB

    Trip history:
    - Trips per vehicle/day: 3 trips
    - Total trips: 10M √ó 3 √ó 365 = 10.95B trips/year
    - Trip record: 1 KB (start, end, distance, efficiency, route)
    - Yearly: 10.95B √ó 1 KB = 10.95 TB/year
    - 7-year retention: 76.65 TB

    User accounts & preferences:
    - Users: 15M √ó 5 KB = 75 GB

    Total storage:
    109 TB (telemetry) + 100 GB (vehicles) + 500 GB (OTA) + 840 GB (DTCs) +
    76.65 TB (trips) + 75 GB (users) ‚âà 187 TB
    ```

    ### Bandwidth Estimates

    ```
    Telemetry ingress:
    - 16,700 events/sec √ó 150 bytes = 2.5 MB/sec
    - Peak: 83,500 events/sec √ó 150 bytes = 12.5 MB/sec ‚âà 100 Mbps

    OTA downloads (egress):
    - Concurrent downloads: 500 vehicles
    - Download speed: 1 MB/sec/vehicle (throttled)
    - 500 √ó 1 MB/sec = 500 MB/sec ‚âà 4 Gbps
    - Peak (2,000 concurrent): 2 GB/sec ‚âà 16 Gbps

    Remote commands (ingress):
    - 405 commands/sec √ó 500 bytes = 202 KB/sec ‚âà 1.6 Mbps

    Fleet dashboard queries (egress):
    - 6 queries/sec √ó 100 KB = 600 KB/sec ‚âà 4.8 Mbps

    Vehicle-to-cloud (total ingress):
    - Telemetry: 2.5 MB/sec
    - Location: 4,860/sec √ó 100 bytes = 486 KB/sec
    - DTCs: 20M/month = 8 events/sec √ó 500 bytes = 4 KB/sec
    - Total: ~3 MB/sec ‚âà 24 Mbps average, 100 Mbps peak

    Cloud-to-vehicle (total egress):
    - OTA: 500 MB/sec (4 Gbps)
    - Commands: 202 KB/sec
    - Config updates: 50 KB/sec
    - Total: ~500 MB/sec ‚âà 4 Gbps average, 16 Gbps peak

    Per-vehicle bandwidth (cellular):
    - Telemetry upload: 150 bytes/sec √ó 100 events/min √∑ 60 = 250 bytes/sec
    - Daily: 250 bytes/sec √ó 86,400 = 21.6 MB/day
    - With OTA (occasional): 50 MB/day average
    ```

    ### Memory Estimates (Caching)

    ```
    Vehicle state cache (hot data):
    - Active vehicles: 7M (daily active)
    - State per vehicle: 5 KB (location, battery, speed, status)
    - 7M √ó 5 KB = 35 GB

    Vehicle metadata cache:
    - All vehicles: 10M √ó 2 KB = 20 GB

    User session cache:
    - Active users: 500K concurrent
    - Session data: 10 KB
    - 500K √ó 10 KB = 5 GB

    OTA campaign state:
    - Active campaigns: 20
    - Vehicles per campaign: 500K
    - State per vehicle: 100 bytes
    - 20 √ó 500K √ó 100 bytes = 1 GB

    ML model inference cache:
    - Predictive maintenance models: 10 GB
    - Anomaly detection models: 5 GB

    Time-series aggregates (recent):
    - 1-hour aggregates: 10M vehicles √ó 1 KB = 10 GB

    Fleet query cache:
    - Popular queries: 5 GB

    Total cache: 35 GB + 20 GB + 5 GB + 1 GB + 15 GB + 10 GB + 5 GB = 91 GB
    ```

    ---

    ## Key Assumptions

    1. Average vehicle drives 1 hour/day (commute)
    2. Telemetry sent at 1 Hz for critical sensors, 0.1 Hz for others
    3. 70% of vehicles are active daily
    4. Cellular connectivity available 95% of the time (LTE/5G)
    5. OTA updates delivered over WiFi when possible (80%), cellular (20%)
    6. Average OTA update size: 500 MB (full), 50 MB (delta)
    7. Remote commands require vehicle to be awake or wake vehicle (2s latency)
    8. Telemetry data compressed 5:1 before cloud storage
    9. 2% of vehicles experience DTC events monthly
    10. Fleet operations (commercial) represent 10% of vehicles

=== "üèóÔ∏è Step 2: High-Level Design"

    ## System Architecture Overview

    **Core Design Principles:**

    1. **Edge-cloud hybrid:** Vehicle gateway for local processing, cloud for analytics
    2. **Time-series first:** Telemetry is time-series data, optimize accordingly
    3. **Security-first:** Zero-trust, E2E encryption, secure boot, OTA signing
    4. **Bandwidth optimization:** Delta updates, compression, adaptive sampling
    5. **Eventual consistency:** Telemetry can tolerate delays, commands cannot
    6. **Versioning & rollback:** All OTA updates versioned with rollback capability
    7. **Multi-region:** Deploy close to vehicle fleets for latency

    ---

    ## Architecture Diagram

    ```mermaid
    graph TB
        subgraph "Vehicle (Edge)"
            Vehicle_Gateway[Vehicle Gateway ECU<br/>Linux/QNX/RTOS]
            CAN_Bus[CAN Bus<br/>Vehicle network]
            ECU_Modules[ECU Modules<br/>Battery, Motor, ADAS, etc.]
            Local_Storage[Local Storage<br/>100GB SSD/eMMC]
            Cellular_Modem[Cellular Modem<br/>LTE/5G]
            WiFi_Module[WiFi Module<br/>OTA downloads]
            GPS_Module[GPS/GNSS]
        end

        subgraph "Client Apps"
            Mobile_App[Mobile App<br/>iOS/Android]
            Web_Dashboard[Fleet Dashboard<br/>Web]
            Service_Portal[Service Portal<br/>Technicians]
        end

        subgraph "Edge/Regional"
            Edge_Gateway[Edge Gateway<br/>Regional PoP]
            Edge_Cache[Edge Cache<br/>CloudFront/CDN]
        end

        subgraph "API Gateway & Auth"
            LB[Load Balancer<br/>Global]
            API_Gateway[API Gateway<br/>GraphQL/gRPC]
            Auth_Service[Auth Service<br/>OAuth 2.0 + mTLS]
            Rate_Limiter[Rate Limiter<br/>Per vehicle/user]
        end

        subgraph "Core Services"
            Vehicle_Service[Vehicle Service<br/>Registry, metadata]
            Telemetry_Service[Telemetry Ingestion<br/>Kafka ingestion]
            Command_Service[Command Service<br/>Remote control]
            OTA_Service[OTA Service<br/>Update management]
            Fleet_Service[Fleet Service<br/>Analytics, monitoring]
            Diagnostic_Service[Diagnostic Service<br/>DTC analysis]
        end

        subgraph "OTA Pipeline"
            Package_Builder[Package Builder<br/>Delta generation]
            Version_Manager[Version Manager<br/>Firmware registry]
            Rollout_Manager[Rollout Manager<br/>Phased deployment]
            Update_Validator[Update Validator<br/>Pre/post checks]
        end

        subgraph "Telemetry Pipeline"
            Kafka_Ingestion[Kafka<br/>Telemetry stream]
            Stream_Processor[Stream Processor<br/>Flink/Spark]
            Aggregator[Aggregator<br/>Time-series rollups]
            Alerting_Engine[Alerting Engine<br/>Anomaly detection]
        end

        subgraph "ML & Analytics"
            Predictive_Maintenance[Predictive Maintenance<br/>ML models]
            Anomaly_Detection[Anomaly Detection<br/>Real-time]
            Battery_Health[Battery Health<br/>SoH/SoC prediction]
            Driving_Behavior[Driving Behavior<br/>Efficiency scoring]
        end

        subgraph "Storage Layer"
            Vehicle_DB[(Vehicle Registry<br/>PostgreSQL<br/>Shard by VIN)]
            Telemetry_DB[(Telemetry Store<br/>InfluxDB/TimescaleDB<br/>Time-series)]
            Blob_Storage[(Blob Storage<br/>S3/GCS<br/>OTA packages)]
            Cache_Layer[(Redis Cluster<br/>Vehicle state, sessions)]
            Graph_DB[(Neo4j<br/>Vehicle relationships)]
        end

        subgraph "External Services"
            Maps_API[Maps API<br/>Google Maps]
            Weather_API[Weather API]
            Cellular_Network[Cellular Networks<br/>AT&T, Verizon, etc.]
            Emergency_Services[Emergency Services<br/>911, OnStar]
        end

        subgraph "Monitoring & Ops"
            Metrics[Prometheus/Datadog<br/>Metrics]
            Logging[ELK Stack<br/>Logs]
            Tracing[Jaeger<br/>Distributed tracing]
            Alerting[PagerDuty<br/>Alerts]
        end

        CAN_Bus --> ECU_Modules
        ECU_Modules --> Vehicle_Gateway
        Vehicle_Gateway --> Local_Storage
        Vehicle_Gateway --> GPS_Module
        Vehicle_Gateway --> Cellular_Modem
        Vehicle_Gateway --> WiFi_Module

        Cellular_Modem --> Cellular_Network
        Cellular_Network --> Edge_Gateway
        WiFi_Module --> Edge_Cache

        Mobile_App --> LB
        Web_Dashboard --> LB
        Service_Portal --> LB

        LB --> API_Gateway
        API_Gateway --> Auth_Service
        Auth_Service --> Rate_Limiter
        Rate_Limiter --> Vehicle_Service
        Rate_Limiter --> Telemetry_Service
        Rate_Limiter --> Command_Service
        Rate_Limiter --> OTA_Service
        Rate_Limiter --> Fleet_Service

        Vehicle_Gateway --> Edge_Gateway
        Edge_Gateway --> Telemetry_Service
        Telemetry_Service --> Kafka_Ingestion
        Kafka_Ingestion --> Stream_Processor
        Stream_Processor --> Aggregator
        Stream_Processor --> Alerting_Engine
        Stream_Processor --> Telemetry_DB

        Command_Service --> Vehicle_Gateway
        Command_Service --> Cache_Layer

        OTA_Service --> Package_Builder
        OTA_Service --> Version_Manager
        OTA_Service --> Rollout_Manager
        Package_Builder --> Blob_Storage
        Rollout_Manager --> Edge_Cache
        Edge_Cache --> Vehicle_Gateway

        Aggregator --> Predictive_Maintenance
        Aggregator --> Anomaly_Detection
        Aggregator --> Battery_Health
        Telemetry_DB --> Predictive_Maintenance
        Predictive_Maintenance --> Alerting_Engine

        Vehicle_Service --> Vehicle_DB
        Fleet_Service --> Telemetry_DB
        Fleet_Service --> Cache_Layer
        Diagnostic_Service --> Telemetry_DB

        Alerting_Engine --> Mobile_App
        Alerting_Engine --> Emergency_Services

        Vehicle_Service --> Metrics
        Telemetry_Service --> Logging
        OTA_Service --> Tracing
        Alerting_Engine --> Alerting
    ```

    ---

    ## Component Breakdown

    ### 1. Vehicle Gateway ECU

    **Purpose:** Edge computing hub in vehicle, orchestrates all cloud communication

    **Responsibilities:**
    - CAN bus data collection and parsing
    - Local telemetry buffering and compression
    - OTA update download and installation
    - Remote command execution
    - Security (encryption, authentication)
    - Edge processing (anomaly detection)

    **Technology Choices:**
    - Hardware: ARM Cortex-A53/A72, 2-4GB RAM, 100GB storage
    - OS: Linux (Yocto), QNX (real-time), or custom RTOS
    - Communication: LTE/5G modem, WiFi, Bluetooth
    - Security: Hardware Security Module (HSM), Secure Element

    ---

    ### 2. Telemetry Ingestion Service

    **Purpose:** High-throughput ingestion of vehicle telemetry data

    **API Design:**

    ```protobuf
    // gRPC API for telemetry ingestion
    service TelemetryService {
      // Batch telemetry upload
      rpc UploadTelemetry(TelemetryBatch) returns (UploadResponse);

      // Streaming telemetry (for real-time events)
      rpc StreamTelemetry(stream TelemetryEvent) returns (StreamResponse);
    }

    message TelemetryBatch {
      string vehicle_id = 1;
      int64 timestamp = 2;
      repeated TelemetryEvent events = 3;
      string signature = 4;  // HMAC for integrity
    }

    message TelemetryEvent {
      string signal_name = 1;  // e.g., "battery_soc", "speed_kmh"
      oneof value {
        double numeric_value = 2;
        string string_value = 3;
        bool boolean_value = 4;
        bytes binary_value = 5;
      }
      int64 timestamp_ms = 6;
      map<string, string> metadata = 7;
    }

    message UploadResponse {
      bool success = 1;
      int32 events_accepted = 2;
      int32 events_rejected = 3;
      repeated string errors = 4;
    }
    ```

    **Data Model (Time-Series):**

    ```python
    # InfluxDB schema
    {
        "measurement": "vehicle_telemetry",
        "tags": {
            "vehicle_id": "VIN_ABC123",
            "signal_name": "battery_soc",
            "model": "Model_Y",
            "region": "us-west"
        },
        "fields": {
            "value": 82.5,
            "unit": "percent"
        },
        "timestamp": 1643712000000000000  # nanoseconds
    }
    ```

    ---

    ### 3. OTA Service

    **Purpose:** Manage over-the-air software updates

    **API Design:**

    ```graphql
    type OTAPackage {
        id: ID!
        name: String!
        version: String!
        target_ecus: [String!]!  # ["infotainment", "battery_mgmt", "autopilot"]
        package_size: Int!       # bytes
        package_url: String!
        delta_from_versions: [String!]
        checksum: String!
        signature: String!
        release_notes: String
        created_at: DateTime!
    }

    type OTACampaign {
        id: ID!
        name: String!
        package: OTAPackage!
        target_vehicles: VehicleFilter!
        rollout_strategy: RolloutStrategy!
        status: CampaignStatus!
        success_rate: Float!
        started_at: DateTime
        completed_at: DateTime
    }

    enum RolloutStrategy {
        IMMEDIATE      # All vehicles at once
        PHASED         # Gradual rollout (1% ‚Üí 10% ‚Üí 100%)
        MANUAL         # Per-vehicle approval
    }

    enum CampaignStatus {
        DRAFT
        SCHEDULED
        IN_PROGRESS
        PAUSED
        COMPLETED
        CANCELLED
    }

    type Mutation {
        createOTAPackage(input: CreatePackageInput!): OTAPackage
        createCampaign(input: CreateCampaignInput!): OTACampaign
        updateCampaignStatus(id: ID!, status: CampaignStatus!): OTACampaign
        rollbackUpdate(vehicle_id: ID!, target_version: String!): UpdateResult
    }

    type Query {
        otaPackage(id: ID!): OTAPackage
        campaign(id: ID!): OTACampaign
        vehicleUpdateStatus(vehicle_id: ID!): UpdateStatus
    }
    ```

    **Update State Machine:**

    ```python
    # Vehicle update status
    {
        "vehicle_id": "VIN_ABC123",
        "campaign_id": "campaign_20240115_v2.5",
        "current_version": "2.4.1",
        "target_version": "2.5.0",
        "status": "downloading",  # pending, downloading, installing, verifying, completed, failed
        "progress_percent": 45,
        "download_speed_mbps": 5.2,
        "estimated_completion": "2024-01-15T14:30:00Z",
        "rollback_available": true,
        "previous_version": "2.4.1",
        "error_code": null,
        "updated_ecus": ["infotainment", "battery_mgmt"],
        "pending_ecus": ["autopilot"]
    }
    ```

    ---

    ### 4. Command Service

    **Purpose:** Execute remote commands on vehicles

    **API Design:**

    ```graphql
    type RemoteCommand {
        id: ID!
        vehicle_id: ID!
        command_type: CommandType!
        parameters: JSON
        status: CommandStatus!
        requested_at: DateTime!
        executed_at: DateTime
        result: CommandResult
    }

    enum CommandType {
        LOCK_DOORS
        UNLOCK_DOORS
        HONK_HORN
        FLASH_LIGHTS
        SET_CLIMATE
        ENABLE_VALET_MODE
        DISABLE_VALET_MODE
        LOCATE_VEHICLE
        REMOTE_START
    }

    enum CommandStatus {
        PENDING       # Queued, waiting for vehicle
        SENT          # Sent to vehicle
        ACKNOWLEDGED  # Vehicle received
        EXECUTING     # In progress
        COMPLETED     # Success
        FAILED        # Error
        TIMEOUT       # No response
    }

    type Mutation {
        sendCommand(input: SendCommandInput!): RemoteCommand
        cancelCommand(id: ID!): Boolean
    }

    input SendCommandInput {
        vehicle_id: ID!
        command_type: CommandType!
        parameters: JSON
        timeout_seconds: Int = 30
    }
    ```

    **Command Execution Flow:**

    ```python
    # Command record
    {
        "command_id": "cmd_abc123",
        "vehicle_id": "VIN_ABC123",
        "command_type": "set_climate",
        "parameters": {
            "temperature": 72,
            "mode": "heat",
            "fan_speed": "auto"
        },
        "status": "pending",
        "requested_at": "2024-01-15T14:00:00Z",
        "timeout_at": "2024-01-15T14:00:30Z",
        "requester": "user_xyz789",
        "result": null
    }
    ```

    ---

    ### 5. Fleet Management Service

    **Purpose:** Commercial fleet operations and analytics

    **Key Features:**

    ```graphql
    type Fleet {
        id: ID!
        name: String!
        organization_id: ID!
        vehicles: [Vehicle!]!
        total_vehicles: Int!
        active_vehicles: Int!
        total_mileage: Float!
        average_utilization: Float!
        health_score: Float!
    }

    type FleetMetrics {
        fleet_id: ID!
        time_range: TimeRange!
        total_trips: Int!
        total_distance_km: Float!
        total_energy_kwh: Float!
        average_efficiency: Float!
        maintenance_events: Int!
        dtc_events: Int!
        uptime_percent: Float!
    }

    type Query {
        fleet(id: ID!): Fleet
        fleetMetrics(fleet_id: ID!, time_range: TimeRange!): FleetMetrics
        vehicleUtilization(fleet_id: ID!): [VehicleUtilization!]!
        maintenanceSchedule(fleet_id: ID!): [MaintenanceEvent!]!
    }
    ```

    ---

    ## Data Flow Examples

    ### Flow 1: Telemetry Collection & Processing

    ```mermaid
    sequenceDiagram
        participant Vehicle as Vehicle Gateway
        participant Edge as Edge Gateway
        participant Ingestion as Telemetry Service
        participant Kafka as Kafka
        participant Processor as Stream Processor
        participant DB as InfluxDB
        participant ML as ML Service
        participant Alert as Alert Service

        Vehicle->>Vehicle: Collect CAN bus data (1 Hz)
        Vehicle->>Vehicle: Buffer & compress (10s batches)
        Vehicle->>Edge: Upload batch via cellular (gRPC)
        Edge->>Ingestion: Forward telemetry
        Ingestion->>Ingestion: Validate & decompress
        Ingestion->>Kafka: Publish events

        Kafka->>Processor: Stream events
        Processor->>Processor: Aggregate & transform
        Processor->>DB: Store time-series data
        Processor->>ML: Feed to ML models

        ML->>ML: Detect anomalies
        alt Anomaly detected
            ML->>Alert: Trigger alert
            Alert->>Vehicle: Push notification
        end
    ```

    ### Flow 2: OTA Update Deployment

    ```mermaid
    sequenceDiagram
        participant Engineer as Engineer
        participant OTA as OTA Service
        participant Builder as Package Builder
        participant Storage as S3/CDN
        participant Rollout as Rollout Manager
        participant Vehicle as Vehicle Gateway
        participant ECU as Target ECU

        Engineer->>OTA: Create update campaign
        OTA->>Builder: Build delta packages
        Builder->>Builder: Generate diffs from v2.4 ‚Üí v2.5
        Builder->>Builder: Sign packages
        Builder->>Storage: Upload packages

        OTA->>Rollout: Start phased rollout (1%)
        Rollout->>Rollout: Select 1% vehicles
        Rollout->>Vehicle: Notify update available

        Vehicle->>Vehicle: Check WiFi connection
        alt WiFi available
            Vehicle->>Storage: Download delta (50 MB)
        else Cellular only
            Vehicle->>Vehicle: Wait for WiFi or user approval
        end

        Vehicle->>Vehicle: Verify signature & checksum
        Vehicle->>Vehicle: Create backup/snapshot
        Vehicle->>ECU: Install update
        ECU->>Vehicle: Installation complete

        Vehicle->>Vehicle: Verify new version
        alt Verification success
            Vehicle->>Rollout: Report success
            Rollout->>Rollout: Continue to 10% rollout
        else Verification failed
            Vehicle->>Vehicle: Automatic rollback
            Vehicle->>Rollout: Report failure
            Rollout->>Rollout: Pause campaign
        end
    ```

=== "üöÄ Step 3: Deep Dive"

    ## 3.1 OTA Update System

    ### Delta Patch Generation

    **Problem:** Full firmware images are 500 MB. Cellular bandwidth is expensive and slow.

    **Solution:** Binary delta patching (only send differences)

    **Implementation:**

    ```python
    import bsdiff4
    import hashlib
    import os

    class DeltaPatchGenerator:
        """
        Generate binary delta patches for OTA updates
        Reduces update size from 500 MB to 50 MB (90% reduction)
        """

        def generate_delta_patch(
            self,
            old_firmware_path: str,
            new_firmware_path: str,
            output_path: str
        ) -> dict:
            """
            Generate delta patch using bsdiff algorithm

            Args:
                old_firmware_path: Path to current firmware
                new_firmware_path: Path to new firmware
                output_path: Path to save delta patch

            Returns:
                Patch metadata
            """
            # Read firmware files
            with open(old_firmware_path, 'rb') as f:
                old_data = f.read()

            with open(new_firmware_path, 'rb') as f:
                new_data = f.read()

            # Generate binary diff
            patch_data = bsdiff4.diff(old_data, new_data)

            # Compress patch (typically 50-70% reduction)
            import gzip
            compressed_patch = gzip.compress(patch_data, compresslevel=9)

            # Write compressed patch
            with open(output_path, 'wb') as f:
                f.write(compressed_patch)

            # Calculate checksums
            old_sha256 = hashlib.sha256(old_data).hexdigest()
            new_sha256 = hashlib.sha256(new_data).hexdigest()
            patch_sha256 = hashlib.sha256(compressed_patch).hexdigest()

            metadata = {
                "old_version_checksum": old_sha256,
                "new_version_checksum": new_sha256,
                "patch_checksum": patch_sha256,
                "old_size_bytes": len(old_data),
                "new_size_bytes": len(new_data),
                "patch_size_bytes": len(compressed_patch),
                "compression_ratio": len(compressed_patch) / len(new_data),
                "algorithm": "bsdiff4+gzip"
            }

            return metadata

        def apply_delta_patch(
            self,
            old_firmware_path: str,
            patch_path: str,
            output_path: str,
            expected_checksum: str
        ) -> bool:
            """
            Apply delta patch to create new firmware
            Run on vehicle gateway

            Returns:
                True if successful, False otherwise
            """
            try:
                # Read old firmware
                with open(old_firmware_path, 'rb') as f:
                    old_data = f.read()

                # Read and decompress patch
                import gzip
                with open(patch_path, 'rb') as f:
                    compressed_patch = f.read()
                patch_data = gzip.decompress(compressed_patch)

                # Apply patch
                new_data = bsdiff4.patch(old_data, patch_data)

                # Verify checksum
                actual_checksum = hashlib.sha256(new_data).hexdigest()
                if actual_checksum != expected_checksum:
                    raise ValueError(f"Checksum mismatch: {actual_checksum} != {expected_checksum}")

                # Write new firmware
                with open(output_path, 'wb') as f:
                    f.write(new_data)

                return True

            except Exception as e:
                print(f"Patch application failed: {e}")
                return False
    ```

    ### Rollback Mechanism

    **Problem:** Failed updates can brick vehicles. Need safe rollback.

    **Solution:** A/B partition scheme (like Android)

    ```cpp
    // Vehicle gateway rollback manager (C++)
    #include <string>
    #include <fstream>
    #include <filesystem>

    class OTARollbackManager {
    private:
        std::string partition_a_path = "/dev/mmcblk0p1";
        std::string partition_b_path = "/dev/mmcblk0p2";
        std::string active_partition_flag = "/boot/active_partition";

    public:
        /**
         * Update strategy:
         * - Always keep one working partition
         * - Install to inactive partition
         * - Switch only after verification
         * - Can revert by switching back
         */

        bool install_update(const std::string& update_path) {
            // 1. Determine current active partition
            std::string active = get_active_partition();
            std::string inactive = (active == "A") ? "B" : "A";
            std::string inactive_path = (inactive == "A") ? partition_a_path : partition_b_path;

            // 2. Write update to inactive partition
            if (!write_to_partition(update_path, inactive_path)) {
                return false;
            }

            // 3. Verify update on inactive partition
            if (!verify_partition(inactive_path)) {
                // Verification failed, inactive partition corrupt
                // Active partition still good, no harm done
                return false;
            }

            // 4. Update bootloader to try new partition on next boot
            set_next_boot_partition(inactive);

            // 5. Reboot to apply update
            // Boot loader will try inactive partition
            // If boot fails 3 times, automatically revert to active
            schedule_reboot(30); // 30 second delay

            return true;
        }

        bool verify_boot_and_finalize() {
            /**
             * Called on first boot after update
             * Runs validation tests
             */
            std::string current = get_active_partition();

            // Run system health checks
            if (!check_can_bus_connectivity()) {
                rollback();
                return false;
            }

            if (!check_critical_services()) {
                rollback();
                return false;
            }

            if (!check_ecu_communication()) {
                rollback();
                return false;
            }

            // All checks passed, commit to new partition
            commit_boot_partition(current);
            return true;
        }

        void rollback() {
            /**
             * Revert to previous partition
             */
            std::string current = get_active_partition();
            std::string previous = (current == "A") ? "B" : "A";

            // Update bootloader to use previous partition
            set_next_boot_partition(previous);

            // Immediate reboot
            schedule_reboot(1);
        }

    private:
        std::string get_active_partition() {
            std::ifstream file(active_partition_flag);
            std::string partition;
            file >> partition;
            return partition;
        }

        void set_next_boot_partition(const std::string& partition) {
            std::ofstream file(active_partition_flag);
            file << partition;
        }

        bool write_to_partition(const std::string& src, const std::string& dst) {
            // Copy update image to partition
            std::ifstream src_file(src, std::ios::binary);
            std::ofstream dst_file(dst, std::ios::binary);
            dst_file << src_file.rdbuf();
            return true;
        }

        bool verify_partition(const std::string& partition_path) {
            // Verify filesystem integrity
            // Check digital signature
            // Run basic boot test
            return true; // Simplified
        }

        bool check_can_bus_connectivity() {
            // Test CAN bus communication
            return true;
        }

        bool check_critical_services() {
            // Verify all critical services running
            return true;
        }

        bool check_ecu_communication() {
            // Ping all ECUs
            return true;
        }

        void commit_boot_partition(const std::string& partition) {
            // Make partition permanent (disable auto-rollback)
            // Remove boot counter
        }

        void schedule_reboot(int delay_seconds) {
            // System reboot
        }
    };
    ```

    ### Phased Rollout Strategy

    **Problem:** Deploy update to 10M vehicles safely without mass failures.

    **Solution:** Gradual rollout with monitoring

    ```python
    class PhaseRolloutManager:
        """
        Phased OTA rollout strategy
        1% ‚Üí 10% ‚Üí 50% ‚Üí 100%
        """

        ROLLOUT_PHASES = [
            {"name": "canary", "percentage": 0.01, "duration_hours": 24, "success_threshold": 0.999},
            {"name": "pilot", "percentage": 0.10, "duration_hours": 48, "success_threshold": 0.995},
            {"name": "wide", "percentage": 0.50, "duration_hours": 72, "success_threshold": 0.99},
            {"name": "full", "percentage": 1.0, "duration_hours": 168, "success_threshold": 0.98}
        ]

        def __init__(self, campaign_id: str):
            self.campaign_id = campaign_id
            self.current_phase = 0

        async def start_rollout(self):
            """Start phased rollout"""
            for phase in self.ROLLOUT_PHASES:
                print(f"Starting phase: {phase['name']} ({phase['percentage']*100}%)")

                # Select vehicles for this phase
                vehicles = await self.select_vehicles_for_phase(phase)

                # Deploy to selected vehicles
                await self.deploy_to_vehicles(vehicles)

                # Monitor for duration
                success = await self.monitor_phase(phase)

                if not success:
                    # Phase failed, halt rollout
                    await self.pause_campaign()
                    await self.alert_engineers(f"Phase {phase['name']} failed")
                    return False

                # Phase succeeded, continue to next
                self.current_phase += 1

            return True

        async def select_vehicles_for_phase(self, phase: dict) -> List[str]:
            """
            Select vehicles for this phase
            Strategy:
            - Geographic diversity (test different regions)
            - Model diversity (test different hardware)
            - Usage diversity (high/low mileage)
            - Avoid critical fleets (emergency services, etc.)
            """
            percentage = phase['percentage']
            previous_percentage = self.ROLLOUT_PHASES[self.current_phase - 1]['percentage'] if self.current_phase > 0 else 0
            new_vehicles_percentage = percentage - previous_percentage

            # Get eligible vehicles for campaign
            all_vehicles = await self.get_campaign_vehicles(self.campaign_id)

            # Exclude already updated vehicles
            updated_vehicles = await self.get_updated_vehicles(self.campaign_id)
            eligible_vehicles = [v for v in all_vehicles if v not in updated_vehicles]

            # Calculate number of vehicles for this phase
            num_vehicles = int(len(all_vehicles) * new_vehicles_percentage)

            # Select diverse subset
            selected = await self.select_diverse_subset(eligible_vehicles, num_vehicles)

            return selected

        async def monitor_phase(self, phase: dict) -> bool:
            """
            Monitor phase success rate
            Check every hour for duration
            """
            duration_hours = phase['duration_hours']
            success_threshold = phase['success_threshold']

            for hour in range(duration_hours):
                await asyncio.sleep(3600)  # Wait 1 hour

                # Get phase metrics
                metrics = await self.get_phase_metrics(phase)

                success_rate = metrics['successful_updates'] / metrics['total_updates']
                print(f"Hour {hour+1}/{duration_hours}: Success rate {success_rate:.2%}")

                # Check if below threshold
                if success_rate < success_threshold:
                    print(f"Success rate {success_rate:.2%} below threshold {success_threshold:.2%}")
                    return False

                # Check for critical failures
                if metrics['critical_failures'] > 0:
                    print(f"Critical failures detected: {metrics['critical_failures']}")
                    return False

            # Phase completed successfully
            return True

        async def pause_campaign(self):
            """Pause rollout, no more vehicles updated"""
            await self.db.update_campaign(
                self.campaign_id,
                status='PAUSED'
            )

        async def alert_engineers(self, message: str):
            """Alert on-call engineers"""
            await self.alerting_service.send_alert(
                severity='critical',
                message=message,
                campaign_id=self.campaign_id
            )
    ```

    ---

    ## 3.2 CAN Bus Data Processing

    ### CAN Bus Protocol

    **Background:** Controller Area Network (CAN) is the standard vehicle communication protocol.

    **Characteristics:**
    - Message-based protocol
    - Each message has ID + 8 bytes data
    - No inherent meaning, requires DBC (Database CAN) file for parsing

    ### Telemetry Parsing

    ```python
    import can
    import cantools
    from typing import Dict, Any

    class CANBusParser:
        """
        Parse CAN bus messages to extract vehicle telemetry
        Uses DBC (Database CAN) file for message definitions
        """

        def __init__(self, dbc_file_path: str):
            # Load DBC file (defines message formats)
            self.db = cantools.database.load_file(dbc_file_path)

            # Initialize CAN interface (SocketCAN on Linux)
            self.bus = can.interface.Bus(channel='can0', bustype='socketcan')

        def start_collection(self, callback):
            """
            Start collecting CAN messages

            Args:
                callback: Function called for each parsed message
            """
            while True:
                # Read CAN message
                message = self.bus.recv()

                # Parse message using DBC
                try:
                    decoded = self.db.decode_message(message.arbitration_id, message.data)

                    # Call callback with parsed data
                    callback({
                        'timestamp': message.timestamp,
                        'message_id': message.arbitration_id,
                        'signals': decoded
                    })

                except KeyError:
                    # Unknown message ID, skip
                    pass

        def parse_battery_status(self, data: bytes) -> Dict[str, Any]:
            """
            Example: Parse battery management system message
            Message ID: 0x123
            Data: 8 bytes

            Byte 0-1: State of Charge (SoC) - 0-100% (0.01% resolution)
            Byte 2-3: Voltage (V) - 0-1000V (0.01V resolution)
            Byte 4-5: Current (A) - -500 to +500A (0.1A resolution)
            Byte 6: Temperature (¬∞C) - -40 to +125¬∞C (1¬∞C resolution)
            Byte 7: Status flags
            """
            # Extract big-endian 16-bit values
            soc_raw = int.from_bytes(data[0:2], byteorder='big')
            voltage_raw = int.from_bytes(data[2:4], byteorder='big')
            current_raw = int.from_bytes(data[4:6], byteorder='big', signed=True)
            temperature_raw = data[6]
            status_flags = data[7]

            # Convert to physical values
            soc_percent = soc_raw * 0.01
            voltage_v = voltage_raw * 0.01
            current_a = current_raw * 0.1
            temperature_c = temperature_raw - 40  # Offset of -40

            return {
                'battery_soc': soc_percent,
                'battery_voltage': voltage_v,
                'battery_current': current_a,
                'battery_temperature': temperature_c,
                'charging': bool(status_flags & 0x01),
                'fast_charging': bool(status_flags & 0x02),
                'battery_warning': bool(status_flags & 0x04),
                'battery_error': bool(status_flags & 0x08)
            }

    # Example DBC file format
    """
    VERSION ""

    BO_ 291 BatteryStatus: 8 BMS
     SG_ StateOfCharge : 0|16@1+ (0.01,0) [0|100] "%" Vector__XXX
     SG_ Voltage : 16|16@1+ (0.01,0) [0|1000] "V" Vector__XXX
     SG_ Current : 32|16@1- (0.1,0) [-500|500] "A" Vector__XXX
     SG_ Temperature : 48|8@1+ (1,-40) [-40|125] "C" Vector__XXX
     SG_ Charging : 56|1@1+ (1,0) [0|1] "" Vector__XXX
     SG_ FastCharging : 57|1@1+ (1,0) [0|1] "" Vector__XXX
    """
    ```

    ### Telemetry Compression & Upload

    ```python
    import gzip
    import json
    from collections import defaultdict
    from datetime import datetime, timedelta

    class TelemetryBuffer:
        """
        Buffer and compress telemetry before upload
        Reduces cellular bandwidth by 80-90%
        """

        def __init__(self, vehicle_id: str, upload_interval_sec: int = 60):
            self.vehicle_id = vehicle_id
            self.upload_interval = upload_interval_sec
            self.buffer = defaultdict(list)
            self.last_upload = datetime.now()

        def add_signal(self, signal_name: str, value: Any, timestamp: datetime):
            """Add signal to buffer"""
            self.buffer[signal_name].append({
                'timestamp': timestamp.isoformat(),
                'value': value
            })

            # Check if buffer should be flushed
            if (datetime.now() - self.last_upload).total_seconds() >= self.upload_interval:
                self.flush()

        def flush(self):
            """
            Compress and upload buffer

            Optimizations:
            1. Delta encoding for slowly changing values
            2. Downsampling for high-frequency signals
            3. Compression (gzip)
            """
            if not self.buffer:
                return

            # Apply delta encoding
            compressed_buffer = self.apply_delta_encoding(self.buffer)

            # Apply downsampling
            compressed_buffer = self.apply_downsampling(compressed_buffer)

            # Serialize to JSON
            json_data = json.dumps({
                'vehicle_id': self.vehicle_id,
                'start_time': self.last_upload.isoformat(),
                'end_time': datetime.now().isoformat(),
                'signals': compressed_buffer
            })

            # Compress with gzip
            compressed_data = gzip.compress(json_data.encode(), compresslevel=9)

            # Upload to cloud
            self.upload_to_cloud(compressed_data)

            # Clear buffer
            self.buffer.clear()
            self.last_upload = datetime.now()

        def apply_delta_encoding(self, buffer: dict) -> dict:
            """
            Delta encoding: Store difference from previous value
            Effective for slowly changing signals (temperature, SoC)

            Example:
            Original: [82.5, 82.5, 82.4, 82.4, 82.3]
            Delta: [82.5, 0, -0.1, 0, -0.1]
            """
            delta_buffer = {}

            for signal_name, values in buffer.items():
                if not values:
                    continue

                # First value is full, rest are deltas
                delta_values = [values[0]]

                for i in range(1, len(values)):
                    prev_value = values[i-1]['value']
                    curr_value = values[i]['value']

                    if isinstance(curr_value, (int, float)):
                        delta = curr_value - prev_value
                        # Only store if different (skip no-change)
                        if delta != 0:
                            delta_values.append({
                                'timestamp': values[i]['timestamp'],
                                'delta': delta
                            })
                    else:
                        # Non-numeric, store as-is if changed
                        if curr_value != prev_value:
                            delta_values.append(values[i])

                delta_buffer[signal_name] = delta_values

            return delta_buffer

        def apply_downsampling(self, buffer: dict) -> dict:
            """
            Downsample high-frequency signals
            Example: GPS at 1 Hz ‚Üí 0.1 Hz when stationary
            """
            downsampled = {}

            for signal_name, values in buffer.items():
                if signal_name in ['gps_latitude', 'gps_longitude']:
                    # Downsample GPS when not moving
                    downsampled[signal_name] = self.adaptive_downsample(values)
                else:
                    downsampled[signal_name] = values

            return downsampled

        def adaptive_downsample(self, values: list) -> list:
            """Keep every Nth sample when value not changing much"""
            if len(values) <= 10:
                return values

            # Calculate variance
            numeric_values = [v['value'] for v in values if isinstance(v.get('value'), (int, float))]
            if not numeric_values:
                return values

            variance = sum((x - sum(numeric_values)/len(numeric_values))**2 for x in numeric_values) / len(numeric_values)

            # If low variance (not changing much), downsample aggressively
            if variance < 0.01:
                return values[::10]  # Keep every 10th sample
            else:
                return values  # Keep all samples

        def upload_to_cloud(self, compressed_data: bytes):
            """Upload via cellular modem"""
            # gRPC call to telemetry service
            # Retry with exponential backoff if failed
            pass
    ```

    ---

    ## 3.3 Remote Command Execution

    ### Vehicle Wake-up

    **Problem:** Vehicles sleep to conserve battery. Commands must wake vehicle first.

    **Solution:** Cellular modem stays on, wakes vehicle gateway

    ```python
    class VehicleWakeupManager:
        """
        Wake vehicle for remote command execution
        Uses cellular modem to send wake signal
        """

        async def execute_remote_command(
            self,
            vehicle_id: str,
            command: dict
        ) -> dict:
            """
            Execute remote command

            Flow:
            1. Check if vehicle is awake
            2. If asleep, send wake signal
            3. Wait for vehicle to wake (2-5 seconds)
            4. Execute command
            5. Return result
            """
            # Check vehicle state
            vehicle_state = await self.redis.hget(f"vehicle:{vehicle_id}", "state")

            if vehicle_state == "asleep":
                # Send wake signal via cellular
                await self.send_wake_signal(vehicle_id)

                # Wait for vehicle to wake (poll every 500ms, timeout 10s)
                awake = await self.wait_for_wakeup(vehicle_id, timeout=10)

                if not awake:
                    return {
                        "status": "failed",
                        "error": "vehicle_unresponsive",
                        "message": "Vehicle did not wake up in time"
                    }

            # Vehicle is awake, execute command
            result = await self.send_command_to_vehicle(vehicle_id, command)

            return result

        async def send_wake_signal(self, vehicle_id: str):
            """
            Send wake signal via cellular network
            Uses SMS or TCP packet to modem
            """
            # Option 1: SMS wake
            # Send SMS to vehicle's modem number
            # Modem receives SMS, triggers interrupt, wakes gateway

            # Option 2: TCP wake packet
            # Send small TCP packet to vehicle's IP
            # Modem maintains persistent TCP connection
            await self.cellular_network.send_wake_packet(vehicle_id)

        async def wait_for_wakeup(self, vehicle_id: str, timeout: int) -> bool:
            """Poll vehicle state until awake or timeout"""
            start_time = time.time()

            while time.time() - start_time < timeout:
                state = await self.redis.hget(f"vehicle:{vehicle_id}", "state")

                if state == "awake":
                    return True

                await asyncio.sleep(0.5)

            return False

        async def send_command_to_vehicle(self, vehicle_id: str, command: dict) -> dict:
            """
            Send command via MQTT/WebSocket
            Vehicle gateway subscribes to command topic
            """
            # Publish to MQTT topic
            topic = f"vehicle/{vehicle_id}/command"
            await self.mqtt_client.publish(topic, json.dumps(command))

            # Wait for acknowledgment (5 second timeout)
            ack = await self.wait_for_ack(vehicle_id, command['command_id'], timeout=5)

            if not ack:
                return {
                    "status": "timeout",
                    "error": "no_acknowledgment"
                }

            # Wait for execution result (30 second timeout)
            result = await self.wait_for_result(vehicle_id, command['command_id'], timeout=30)

            return result
    ```

    ### Command Security

    ```python
    from cryptography.hazmat.primitives import hashes, serialization
    from cryptography.hazmat.primitives.asymmetric import rsa, padding
    import time

    class SecureCommandManager:
        """
        Secure remote command execution

        Security measures:
        1. RSA signature verification
        2. Timestamp validation (prevent replay attacks)
        3. Command authorization
        4. Rate limiting
        """

        def __init__(self, private_key_path: str):
            # Load server's private key
            with open(private_key_path, 'rb') as f:
                self.private_key = serialization.load_pem_private_key(
                    f.read(),
                    password=None
                )

        def create_signed_command(self, command: dict) -> dict:
            """
            Create command with RSA signature
            Vehicle verifies signature using server's public key
            """
            # Add timestamp
            command['timestamp'] = int(time.time())
            command['nonce'] = os.urandom(16).hex()

            # Serialize command
            command_json = json.dumps(command, sort_keys=True)

            # Sign command
            signature = self.private_key.sign(
                command_json.encode(),
                padding.PSS(
                    mgf=padding.MGF1(hashes.SHA256()),
                    salt_length=padding.PSS.MAX_LENGTH
                ),
                hashes.SHA256()
            )

            return {
                'command': command,
                'signature': signature.hex()
            }

    class VehicleCommandVerifier:
        """
        Runs on vehicle gateway
        Verifies command signature before execution
        """

        def __init__(self, public_key_path: str):
            # Load server's public key
            with open(public_key_path, 'rb') as f:
                self.public_key = serialization.load_pem_public_key(f.read())

        def verify_command(self, signed_command: dict) -> bool:
            """
            Verify command signature and freshness

            Returns:
                True if command is valid, False otherwise
            """
            command = signed_command['command']
            signature = bytes.fromhex(signed_command['signature'])

            # Check timestamp (prevent replay attacks)
            command_timestamp = command['timestamp']
            current_timestamp = int(time.time())

            # Reject if older than 60 seconds
            if abs(current_timestamp - command_timestamp) > 60:
                print(f"Command timestamp too old: {current_timestamp - command_timestamp}s")
                return False

            # Verify signature
            command_json = json.dumps(command, sort_keys=True)

            try:
                self.public_key.verify(
                    signature,
                    command_json.encode(),
                    padding.PSS(
                        mgf=padding.MGF1(hashes.SHA256()),
                        salt_length=padding.PSS.MAX_LENGTH
                    ),
                    hashes.SHA256()
                )
                return True

            except Exception as e:
                print(f"Signature verification failed: {e}")
                return False
    ```

    ---

    ## 3.4 Predictive Maintenance ML

    ### Battery Health Prediction

    ```python
    import numpy as np
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.preprocessing import StandardScaler

    class BatteryHealthPredictor:
        """
        Predict battery State of Health (SoH) and Remaining Useful Life (RUL)

        Features:
        - Charge/discharge cycles
        - Temperature history
        - Fast charging frequency
        - Depth of discharge
        - Age (time)
        """

        def __init__(self):
            self.model = RandomForestRegressor(n_estimators=100)
            self.scaler = StandardScaler()

        def extract_features(self, vehicle_telemetry: dict) -> np.array:
            """
            Extract features from vehicle telemetry

            Args:
                vehicle_telemetry: Historical telemetry data

            Returns:
                Feature vector
            """
            # Query time-series database for battery data
            battery_data = self.query_battery_history(
                vehicle_telemetry['vehicle_id'],
                days=90
            )

            features = []

            # 1. Total charge cycles
            charge_cycles = self.count_charge_cycles(battery_data)
            features.append(charge_cycles)

            # 2. Average temperature
            avg_temp = np.mean([d['temperature'] for d in battery_data])
            features.append(avg_temp)

            # 3. Max temperature
            max_temp = np.max([d['temperature'] for d in battery_data])
            features.append(max_temp)

            # 4. Fast charging frequency (% of charges)
            fast_charge_freq = self.count_fast_charges(battery_data) / charge_cycles
            features.append(fast_charge_freq)

            # 5. Average depth of discharge
            avg_dod = self.calculate_avg_dod(battery_data)
            features.append(avg_dod)

            # 6. Total energy throughput (kWh)
            total_energy = self.calculate_energy_throughput(battery_data)
            features.append(total_energy)

            # 7. Age in days
            age_days = vehicle_telemetry['age_days']
            features.append(age_days)

            # 8. Current SoH (from BMS)
            current_soh = battery_data[-1]['soh'] if battery_data else 100
            features.append(current_soh)

            return np.array(features)

        def predict_future_soh(
            self,
            vehicle_id: str,
            horizon_days: int = 365
        ) -> dict:
            """
            Predict battery SoH at future date

            Returns:
                Prediction with confidence interval
            """
            # Extract current features
            telemetry = self.get_vehicle_telemetry(vehicle_id)
            features = self.extract_features(telemetry)

            # Predict SoH at horizon
            # Project future usage based on historical patterns
            future_features = self.project_future_features(features, horizon_days)

            # Scale features
            scaled_features = self.scaler.transform([future_features])

            # Predict
            predicted_soh = self.model.predict(scaled_features)[0]

            # Get confidence interval from tree predictions
            tree_predictions = [tree.predict([scaled_features[0]]) for tree in self.model.estimators_]
            std_dev = np.std(tree_predictions)

            return {
                'vehicle_id': vehicle_id,
                'horizon_days': horizon_days,
                'predicted_soh': predicted_soh,
                'confidence_interval_95': (
                    max(0, predicted_soh - 1.96 * std_dev),
                    min(100, predicted_soh + 1.96 * std_dev)
                ),
                'alert': predicted_soh < 80  # Alert if < 80% SoH
            }

        def detect_anomalies(self, vehicle_id: str) -> list:
            """
            Detect battery anomalies

            Anomalies:
            - Sudden SoH drop
            - Temperature spikes
            - Capacity degradation faster than expected
            """
            anomalies = []

            # Get recent data
            recent_data = self.query_battery_history(vehicle_id, days=7)
            if not recent_data:
                return anomalies

            # Check for SoH drop
            soh_values = [d['soh'] for d in recent_data]
            soh_drop = max(soh_values) - min(soh_values)
            if soh_drop > 5:  # 5% drop in 7 days
                anomalies.append({
                    'type': 'sudden_soh_drop',
                    'severity': 'high',
                    'description': f'SoH dropped {soh_drop:.1f}% in 7 days',
                    'recommended_action': 'Schedule service inspection'
                })

            # Check for temperature anomalies
            temperatures = [d['temperature'] for d in recent_data]
            if max(temperatures) > 60:  # > 60¬∞C
                anomalies.append({
                    'type': 'high_temperature',
                    'severity': 'critical',
                    'description': f'Battery temperature reached {max(temperatures):.1f}¬∞C',
                    'recommended_action': 'Immediate inspection required'
                })

            return anomalies
    ```

=== "‚ö° Step 4: Scale & Optimize"

    ## 4.1 Bottlenecks & Solutions

    ### Bottleneck 1: Telemetry Ingestion (16,700 events/sec)

    **Problem:** 1.44B events/day, peaks at 83,500 events/sec

    **Solutions:**

    1. **Kafka partitioning:**
    ```python
    # Partition by vehicle_id for parallelism
    num_partitions = 100
    partition = hash(vehicle_id) % num_partitions

    # Each partition handled by separate consumer
    # Scale to 100 consumers for 100 partitions
    # Per-consumer throughput: 835 events/sec (manageable)
    ```

    2. **Batching:**
    ```python
    # Vehicle batches 100 events before upload
    # Reduces API calls from 1.44B/day to 14.4M/day
    # 100x reduction in overhead
    ```

    3. **Edge aggregation:**
    ```python
    # Aggregate at regional edge before cloud
    # 1-minute aggregates: 16,700 events/sec ‚Üí 279 aggregates/sec
    # 60x reduction
    ```

    ### Bottleneck 2: OTA Download Bandwidth (16 Gbps peak)

    **Problem:** 2,000 concurrent downloads √ó 1 MB/sec = 16 Gbps

    **Solutions:**

    1. **CDN (CloudFront/Akamai):**
    ```
    # Distribute packages globally
    # Edge caching reduces origin load by 95%
    # Origin: 16 Gbps ‚Üí 800 Mbps
    ```

    2. **Torrent-style P2P:**
    ```python
    # Vehicles download from each other (Tesla does this)
    # Reduces cloud bandwidth by 80%
    # Vehicles in same area share delta packages
    ```

    3. **WiFi-only updates:**
    ```python
    # Default to WiFi (free, faster)
    # Cellular only for critical updates
    # Reduces cellular costs by 80%
    ```

    ### Bottleneck 3: Time-Series Storage (216 GB/day)

    **Problem:** 544 TB for 7-year retention

    **Solutions:**

    1. **Tiered storage:**
    ```python
    # Hot tier (7 days): InfluxDB, full resolution
    # Warm tier (30 days): 1-minute aggregates, 60x smaller
    # Cold tier (7 years): 1-hour aggregates, S3 Glacier
    #
    # Total: 1.5 TB (hot) + 10 TB (warm) + 20 TB (cold) = 31.5 TB
    # 94% reduction
    ```

    2. **Compression:**
    ```python
    # Gorilla compression (time-series specific)
    # Compression ratio: 10:1 for typical signals
    # 544 TB ‚Üí 54 TB
    ```

    3. **Sampling:**
    ```python
    # Adaptive sampling based on variance
    # Low variance (stationary): 0.1 Hz
    # High variance (driving): 1 Hz
    # Reduces storage by 50%
    ```

    ---

    ## 4.2 Trade-offs

    ### Trade-off 1: Real-time vs Batched Telemetry

    | Aspect | Real-time (streaming) | Batched |
    |--------|----------------------|---------|
    | **Latency** | < 5s | 60s |
    | **Bandwidth** | High (always-on) | Low (periodic) |
    | **Battery** | Higher drain | Lower drain |
    | **Cost** | $10/vehicle/month | $2/vehicle/month |
    | **Use Case** | Critical alerts | General analytics |

    **Decision:** Hybrid approach
    - Critical signals (airbag, collision): Real-time
    - Normal telemetry: 60s batches
    - Saves 80% bandwidth, minimal latency impact

    ### Trade-off 2: Full vs Delta OTA Updates

    | Aspect | Full Update | Delta Update |
    |--------|-------------|--------------|
    | **Size** | 500 MB | 50 MB |
    | **Complexity** | Simple | Complex (patching) |
    | **Risk** | Lower | Higher (patch failure) |
    | **Bandwidth** | High | Low |
    | **Time** | 8 minutes (LTE) | 48 seconds |

    **Decision:** Delta by default, full fallback
    - 90% bandwidth savings
    - Rollback available if delta fails
    - Full update as backup

    ### Trade-off 3: Edge vs Cloud Processing

    | Aspect | Edge (Vehicle) | Cloud |
    |--------|----------------|-------|
    | **Latency** | 1ms | 100ms |
    | **Compute** | Limited (1-2 CPU cores) | Unlimited |
    | **ML Models** | Simple | Complex (deep learning) |
    | **Privacy** | High (data stays local) | Lower |
    | **Updates** | Requires OTA | Instant |
    | **Cost** | Hardware ($50-100) | Cloud ($$$) |

    **Decision:** Hybrid
    - Edge: Anomaly detection, basic diagnostics
    - Cloud: Predictive maintenance ML, fleet analytics
    - Best of both worlds

    ---

    ## 4.3 Security Considerations

    ### Multi-layer Security

    ```
    Layer 1: Network Security
    - TLS 1.3 for all communication
    - Certificate pinning
    - VPN tunnels for sensitive operations

    Layer 2: Authentication
    - mTLS (mutual TLS) for vehicle-cloud
    - OAuth 2.0 for user-cloud
    - Hardware Security Module (HSM) in vehicle

    Layer 3: Authorization
    - Role-based access control (RBAC)
    - Time-limited tokens (15 min expiry)
    - Geo-fencing (only allow commands from owner's location)

    Layer 4: Data Encryption
    - AES-256 for data at rest
    - E2E encryption for sensitive commands (unlock)
    - Homomorphic encryption for privacy-preserving analytics

    Layer 5: Code Signing
    - All OTA packages signed with RSA-4096
    - Secure boot chain verification
    - Rollback protection
    ```

    ### Threat Mitigation

    | Threat | Mitigation |
    |--------|------------|
    | **Man-in-the-middle** | TLS 1.3, certificate pinning |
    | **Replay attacks** | Timestamp + nonce validation |
    | **Stolen credentials** | Short-lived tokens, biometric auth |
    | **Malicious OTA** | Code signing, phased rollout, rollback |
    | **DDoS** | Rate limiting, API gateway |
    | **Vehicle theft** | Remote disable, GPS tracking |

    ---

    ## 4.4 Cost Optimization

    ### Monthly Infrastructure Cost (10M vehicles)

    ```
    Compute (EC2/Kubernetes):
    - API servers: 100 instances √ó $500 = $50,000
    - Stream processors (Flink): 50 instances √ó $800 = $40,000
    - ML inference: 20 GPU instances √ó $2,000 = $40,000
    Subtotal: $130,000

    Storage:
    - InfluxDB (time-series): 100 nodes √ó $1,000 = $100,000
    - PostgreSQL (vehicle registry): 20 shards √ó $800 = $16,000
    - S3 (OTA packages + cold storage): 600 TB √ó $20/TB = $12,000
    - Redis (cache): 50 nodes √ó $500 = $25,000
    Subtotal: $153,000

    Messaging:
    - Kafka: 100 brokers √ó $500 = $50,000

    Bandwidth:
    - CDN (OTA): 5 PB/month √ó $50/TB = $250,000
    - Cellular data: 10M vehicles √ó 50 MB/day √ó 30 √ó $0.10/GB = $1,500,000
    Subtotal: $1,750,000

    External APIs:
    - Maps (routes): 10M requests/day √ó $0.005 = $150,000
    - Weather: $5,000
    Subtotal: $155,000

    Total: $2,238,000/month
    Per vehicle: $2,238,000 / 10M = $0.22/vehicle/month
    ```

    ### Cost Optimization Strategies

    1. **Cellular bandwidth (70% of cost):**
    ```python
    # WiFi-first strategy
    # 80% of telemetry over WiFi (free)
    # Savings: $1,200,000/month (80% of $1.5M)

    # Adaptive sampling
    # Reduce sampling when stationary
    # Savings: $300,000/month (20% reduction)

    # Total cellular savings: $1.5M ‚Üí $300K (80% reduction)
    ```

    2. **Storage costs:**
    ```python
    # Aggressive tiering
    # 7 days hot, 23 days warm, rest cold
    # Savings: $70,000/month (70% reduction)
    ```

    3. **Spot instances:**
    ```python
    # Use spot for batch processing (ML training)
    # 70% cheaper than on-demand
    # Savings: $28,000/month
    ```

    **Optimized cost: $500K/month ($0.05/vehicle/month)**

    ---

    ## 4.5 Monitoring & Observability

    ### Key Metrics

    ```python
    # Telemetry ingestion
    telemetry_events_per_second = Gauge(
        'connected_car_telemetry_events_per_second',
        'Telemetry events ingested per second'
    )

    telemetry_lag_seconds = Histogram(
        'connected_car_telemetry_lag_seconds',
        'Lag from vehicle timestamp to cloud ingestion',
        buckets=[1, 5, 10, 30, 60, 120, 300]
    )

    # OTA updates
    ota_download_speed_mbps = Histogram(
        'connected_car_ota_download_speed_mbps',
        'OTA package download speed',
        buckets=[0.5, 1, 2, 5, 10, 20]
    )

    ota_success_rate = Gauge(
        'connected_car_ota_success_rate',
        'OTA update success rate by campaign',
        ['campaign_id']
    )

    # Remote commands
    command_latency_seconds = Histogram(
        'connected_car_command_latency_seconds',
        'Time from command request to execution',
        buckets=[1, 2, 5, 10, 30, 60]
    )

    # Vehicle health
    vehicles_online = Gauge(
        'connected_car_vehicles_online',
        'Number of vehicles currently online'
    )

    dtc_events_per_hour = Counter(
        'connected_car_dtc_events_total',
        'Diagnostic trouble code events',
        ['dtc_code', 'severity']
    )

    # ML predictions
    battery_soh_predictions = Histogram(
        'connected_car_battery_soh_predicted',
        'Predicted battery State of Health',
        buckets=[70, 75, 80, 85, 90, 95, 100]
    )
    ```

    ### Alerting Rules

    ```yaml
    # Critical alerts
    - alert: HighOTAFailureRate
      expr: ota_success_rate < 0.95
      for: 1h
      annotations:
        summary: "OTA campaign {{ $labels.campaign_id }} has < 95% success rate"
        action: "Pause campaign, investigate failures"

    - alert: TelemetryIngestionLag
      expr: telemetry_lag_seconds > 60
      for: 5m
      annotations:
        summary: "Telemetry ingestion lag > 60 seconds"
        action: "Check Kafka consumer lag, scale processors"

    - alert: VehiclesMassOffline
      expr: (vehicles_online / vehicles_total) < 0.8
      for: 10m
      annotations:
        summary: "More than 20% of vehicles offline"
        severity: critical
        action: "Check cellular connectivity, API gateway"

    - alert: BatteryCriticalTemperature
      expr: battery_temperature_celsius > 60
      annotations:
        summary: "Vehicle {{ $labels.vehicle_id }} battery > 60¬∞C"
        severity: critical
        action: "Alert owner, recommend immediate stop"
    ```

---

## Real-World Implementations

### Tesla

**Architecture highlights:**
- Custom Vehicle Compute Platform (ARM + NVIDIA GPU)
- OTA updates for entire vehicle software stack (infotainment to autopilot)
- Over-the-air ML model updates (Autopilot improvements)
- Fleet learning: Collect edge cases from all vehicles, improve models
- P2P OTA distribution among vehicles
- AWS backend (EC2, S3, DynamoDB, Kinesis)

**Scale:**
- 5M+ vehicles globally
- 10+ major OTA updates per year
- Petabytes of telemetry data collected daily

**Innovations:**
- Full self-driving (FSD) beta distributed via OTA
- Shadow mode: Test new features without vehicle control
- Fleet-wide data collection for rare events

### GM OnStar

**Architecture highlights:**
- Embedded cellular modem in all vehicles
- Remote diagnostics and emergency response
- Stolen vehicle tracking and slowdown
- Cloud-based service platform (Azure)
- Integration with GM mobile apps

**Scale:**
- 20M+ active subscribers
- 24/7 emergency response center
- Remote commands: lock/unlock, remote start

**Key features:**
- Automatic crash notification (ACN)
- Vehicle health reports via email
- Family location tracking

### BMW ConnectedDrive

**Architecture highlights:**
- Integrated SIM card in vehicles
- Remote services platform
- Concierge services (human-assisted)
- Connected navigation with real-time traffic

**Innovations:**
- Digital Key (smartphone as key)
- Remote Software Upgrade (RSU) via OTA
- Parking assistance with remote view

---

## References & Further Reading

**Standards & Protocols:**
- [ISO 26262](https://www.iso.org/standard/68383.html) - Automotive functional safety
- [CAN Bus Protocol](https://www.kvaser.com/about-can/) - Controller Area Network
- [UDS Protocol (ISO 14229)](https://www.iso.org/standard/55283.html) - Unified Diagnostic Services
- [SOME/IP](https://some-ip.com/) - Scalable service-Oriented MiddlewarE over IP
- [AUTOSAR](https://www.autosar.org/) - Automotive software architecture

**Security:**
- [UNECE WP.29](https://unece.org/transport/vehicle-regulations-wp29) - UN regulations on cybersecurity
- [SAE J3061](https://www.sae.org/standards/content/j3061_201601/) - Cybersecurity guidebook

**OTA Updates:**
- [Uptane](https://uptane.github.io/) - Secure OTA update framework
- [The Update Framework (TUF)](https://theupdateframework.io/) - Software update security

**Platform Documentation:**
- [AWS IoT Core for Automotive](https://aws.amazon.com/iot/solutions/connected-mobility/)
- [Azure IoT for Automotive](https://azure.microsoft.com/en-us/solutions/automotive/)
- [Google Cloud for Automotive](https://cloud.google.com/solutions/automotive)

**Research Papers:**
- "Over-the-Air Software Updates in the Automotive Industry" - IEEE
- "Security Analysis of Automotive CAN Bus Networks" - USENIX Security
- "Battery State-of-Health Estimation Using Machine Learning" - IEEE Transactions

**Books:**
- *Automotive Ethernet* by Kirsten Matheus and Thomas K√∂nigseder
- *Connected Car: Networked Vehicles and Autonomous Mobility* by Wiley
- *Cybersecurity for Connected Cars* by Marco Vieira

---

## Interview Tips

1. **Start with architecture:** Explain vehicle gateway, cloud services, edge-cloud hybrid clearly
2. **Emphasize security:** Connected cars control physical assets, security is paramount
3. **Discuss OTA complexity:** Delta patching, rollback, phased rollout - show you understand risk
4. **CAN bus knowledge:** Show familiarity with automotive protocols (CAN, LIN, FlexRay)
5. **Scale discussion:** 10M vehicles generating 1B events/day - talk about Kafka, time-series DB
6. **Bandwidth optimization:** Cellular data is expensive, compression and batching critical
7. **ML use cases:** Predictive maintenance, battery health, anomaly detection
8. **Regulatory compliance:** Mention ISO 26262, GDPR, data retention requirements

**Common follow-up questions:**
- How do you prevent a malicious OTA update from bricking all vehicles?
- What happens if vehicle loses cellular connectivity during OTA update?
- How do you handle CAN bus data parsing for 50 different ECUs?
- How would you implement emergency vehicle immobilization (for stolen vehicle)?
- How do you ensure privacy of vehicle location data?
- What's your strategy for handling a critical security vulnerability discovered in deployed vehicles?
- How would you scale from 10M to 100M vehicles?

---

**Last Updated:** 2026-02-05
**Document Version:** 1.0
**Author:** System Design Interview Preparation
