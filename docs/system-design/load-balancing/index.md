# Load Balancing & Traffic Distribution ‚öñÔ∏è

Master load balancing strategies, algorithms, and implementations for building scalable distributed systems that efficiently distribute traffic across multiple servers.

## üéØ Understanding Load Balancing

### What is Load Balancing?

**Definition:** Load balancing is the process of distributing incoming network traffic across multiple backend servers to ensure no single server becomes overwhelmed, improving application availability, responsiveness, and fault tolerance.

**Core Benefits:**
- **High Availability**: Eliminates single points of failure
- **Scalability**: Handles increased load by adding more servers
- **Performance**: Reduces response times through load distribution
- **Fault Tolerance**: Continues operation when servers fail
- **Resource Optimization**: Maximizes server utilization

### Load Balancing Layers

=== "üîó Layer 4 (Transport Layer)"

    **Operation Level:** TCP/UDP level
    
    **How It Works:**
    - Routes traffic based on IP address and port
    - No inspection of application data
    - Faster processing with lower latency
    - Protocol-agnostic forwarding
    
    **Best For:**
    - High-performance applications requiring ultra-low latency
    - Non-HTTP protocols (FTP, SMTP, database connections)
    - Simple load distribution without content-based routing
    
    **Limitations:**
    - Cannot make routing decisions based on content
    - Limited visibility into application health
    - No application-specific optimization

=== "üåê Layer 7 (Application Layer)"

    **Operation Level:** HTTP/HTTPS application level
    
    **How It Works:**
    - Inspects HTTP headers, URLs, and content
    - Routes based on application-specific criteria
    - Can modify requests and responses
    - Supports advanced routing rules
    
    **Best For:**
    - Web applications requiring content-based routing
    - Microservices with different API endpoints
    - Applications needing SSL termination
    - Complex routing and transformation requirements
    
    **Capabilities:**
    - URL-based routing (`/api/*` to API servers)
    - Header-based routing (mobile vs desktop)
    - SSL termination and re-encryption
    - Request/response modification

=== "üåç DNS Load Balancing"

    **Operation Level:** Domain Name System level
    
    **How It Works:**
    - Returns different IP addresses for the same domain
    - Client connects directly to returned server
    - Simple round-robin or geographic distribution
    - Minimal infrastructure required
    
    **Advantages:**
    - Geographic distribution capabilities
    - Disaster recovery across regions
    - No single point of failure
    - Cost-effective for global distribution
    
    **Limitations:**
    - No real-time health checking
    - DNS caching delays updates
    - Limited control over traffic distribution
    - Cannot handle session affinity effectively

## ÔøΩ Load Balancing Algorithms

Understanding how different algorithms distribute traffic and when to use each approach:

=== "üîÑ Round Robin"

    **Strategy:** Distributes requests sequentially across available servers
    
    **How It Works:**
    1. Maintain list of healthy servers
    2. Send next request to next server in sequence
    3. Return to first server after reaching the end
    
    **Best For:**
    - Servers with similar capacity and performance
    - Uniform request processing times
    - Simple applications without session requirements
    
    **Advantages:**
    - ‚úÖ Simple to implement and understand
    - ‚úÖ Equal distribution when servers are identical
    - ‚úÖ Low computational overhead
    
    **Disadvantages:**
    - ‚ùå Doesn't account for server capacity differences
    - ‚ùå Can overload slower servers
    - ‚ùå No consideration for current server load

=== "‚öñÔ∏è Weighted Round Robin"

    **Strategy:** Distributes requests based on server capacity/weight
    
    **How It Works:**
    - Assign weights to servers based on capacity
    - Higher weight servers receive more requests
    - Rotate through servers proportional to weights
    
    **Weight Assignment Factors:**
    - CPU cores and processing power
    - Available memory and storage
    - Network bandwidth capacity
    - Historical performance metrics
    
    **Best For:**
    - Heterogeneous server environments
    - Servers with different specifications
    - Gradual traffic shifting (blue-green deployments)
    
    **Example Weight Distribution:**
    - Server A (8 cores): Weight 4
    - Server B (4 cores): Weight 2  
    - Server C (2 cores): Weight 1
    - Result: A gets 4/7, B gets 2/7, C gets 1/7 of traffic

=== "üîó Least Connections"

    **Strategy:** Routes new requests to server with fewest active connections
    
    **How It Works:**
    1. Track active connections per server
    2. Select server with minimum connection count
    3. Update connection count as requests complete
    
    **Best For:**
    - Applications with varying request durations
    - Long-lived connections (WebSockets, streaming)
    - Database connection pooling
    
    **Advantages:**
    - ‚úÖ Better load distribution for varying request times
    - ‚úÖ Prevents overloading slow servers
    - ‚úÖ Adapts to real-time server performance
    
    **Considerations:**
    - Connection count doesn't always reflect actual load
    - Requires tracking connection state
    - May not account for request complexity

=== "üéØ IP Hash"

    **Strategy:** Routes requests based on client IP address hash
    
    **How It Works:**
    1. Hash client IP address
    2. Map hash to specific server using modulo operation
    3. Same client always reaches same server
    
    **Session Affinity Benefits:**
    - Maintains user session state on specific server
    - Enables server-side session storage
    - Consistent user experience across requests
    
    **Best For:**
    - Applications requiring session affinity
    - Server-side session storage
    - Applications with user-specific caching
    
    **Limitations:**
    - Uneven distribution if client IPs cluster
    - Reduced failover capabilities
    - Server addition/removal affects mappings

=== "üìä Weighted Least Connections"

    **Strategy:** Combines server weights with connection counts
    
    **How It Works:**
    - Calculate load ratio: `active_connections / server_weight`
    - Route to server with lowest load ratio
    - Balances both capacity and current load
    
    **Formula:**
    ```
    Load Ratio = Active Connections √∑ Server Weight
    Selected Server = min(Load Ratio across all servers)
    ```
    
    **Best For:**
    - Heterogeneous environments with varying request durations
    - Applications requiring both capacity and load awareness
    - High-performance requirements with mixed server specs

=== "üé≤ Random & Weighted Random"

    **Strategy:** Selects servers randomly, optionally with weights
    
    **Random Selection:**
    - Simple random choice among healthy servers
    - Good statistical distribution over time
    - No state tracking required
    
    **Weighted Random:**
    - Random selection biased by server weights
    - Probability proportional to server capacity
    - Combines randomness with capacity awareness
    
    **Best For:**
    - Stateless applications
    - Simple implementations
    - Testing and development environments

## üìä Algorithm Selection Guide

### Decision Matrix

| Scenario | Recommended Algorithm | Reason |
|----------|----------------------|---------|
| **Identical Servers** | Round Robin | Simple and evenly distributes load |
| **Different Server Specs** | Weighted Round Robin | Accounts for capacity differences |
| **Varying Request Times** | Least Connections | Adapts to actual server load |
| **Session Requirements** | IP Hash | Maintains session affinity |
| **Mixed Environment** | Weighted Least Connections | Best of both worlds |
| **Stateless + Simple** | Random | Low overhead, good distribution |

## üèóÔ∏è Load Balancer Technologies

=== "üîß HAProxy"

    **Type:** Layer 4/7 Load Balancer
    
    **Key Features:**
    - Advanced traffic routing and ACLs
    - High-performance TCP/HTTP load balancing
    - Built-in health checking and monitoring
    - SSL termination and compression
    - Stick tables for session persistence
    
    **Best For:**
    - High-traffic web applications
    - Complex routing requirements
    - On-premises deployments
    - Performance-critical applications
    
    **Performance:** Can handle 100K+ concurrent connections

=== "üåê Nginx"

    **Type:** Layer 7 Web Server + Load Balancer
    
    **Key Features:**
    - Reverse proxy with load balancing
    - HTTP/2 and WebSocket support
    - Static content serving
    - Caching and compression
    - Easy configuration and deployment
    
    **Best For:**
    - Web applications and APIs
    - Microservices architectures
    - Static content delivery
    - Simple to moderate complexity routing
    
    **Advantages:** Combines web server and load balancer functionality

=== "‚òÅÔ∏è Cloud Load Balancers"

    **AWS Application Load Balancer (ALB):**
    - Layer 7 HTTP/HTTPS load balancing
    - Path and host-based routing
    - Integration with AWS services
    - Auto-scaling and health checks
    
    **AWS Network Load Balancer (NLB):**
    - Layer 4 TCP/UDP load balancing
    - Ultra-high performance (millions of requests/sec)
    - Static IP addresses
    - Cross-zone load balancing
    
    **Best For:**
    - Cloud-native applications
    - Auto-scaling environments
    - Integration with cloud services
    - Global distribution

## üîç Health Checks & Monitoring

### Health Check Types

=== "üîç Active Health Checks"

    **How They Work:**
    - Load balancer probes backend servers
    - Regular HTTP/TCP requests to health endpoints
    - Remove unhealthy servers from rotation
    - Re-add servers when they recover
    
    **Configuration Parameters:**
    - **Check Interval**: How often to check (30-60 seconds)
    - **Timeout**: Max time to wait for response (5-10 seconds)
    - **Healthy Threshold**: Consecutive successes to mark healthy (2-3)
    - **Unhealthy Threshold**: Consecutive failures to mark unhealthy (3-5)
    
    **Health Check Endpoints:**
    - Simple status check: `GET /health`
    - Deep health check: `GET /health/deep`
    - Database connectivity: `GET /health/db`
    - Dependency checks: `GET /health/dependencies`

=== "üìä Passive Health Checks"

    **How They Work:**
    - Monitor actual request success/failure rates
    - Track response times and error rates
    - Gradually reduce traffic to slow servers
    - Circuit breaker pattern implementation
    
    **Monitoring Metrics:**
    - Response time percentiles (P50, P95, P99)
    - Error rate (4xx, 5xx responses)
    - Connection failures and timeouts
    - Request queue depths
    
    **Adaptive Behavior:**
    - Reduce traffic to slow servers
    - Implement circuit breaker patterns
    - Automatic failover and recovery

### Key Metrics to Monitor

=== "üìà Performance Metrics"

    **Request Metrics:**
    - Requests per second (RPS)
    - Response time (latency)
    - Error rate (percentage)
    - Queue depth and wait times
    
    **Server Metrics:**
    - CPU and memory utilization
    - Active connection counts
    - Network bandwidth usage
    - Disk I/O and storage usage
    
    **Load Balancer Metrics:**
    - Traffic distribution across servers
    - Health check success rates
    - SSL handshake times
    - Connection pool utilization

=== "üö® Alerting Thresholds"

    **Critical Alerts:**
    - Error rate > 5%
    - Response time > 2 seconds (P95)
    - Server availability < 80%
    - Queue depth > 100 requests
    
    **Warning Alerts:**
    - Error rate > 1%
    - Response time > 1 second (P95)
    - CPU utilization > 80%
    - Memory usage > 85%

## ‚öôÔ∏è Advanced Strategies

=== "üîÑ Session Affinity (Sticky Sessions)"

    **Implementation Approaches:**
    
    **Cookie-Based Affinity:**
    - Load balancer sets session cookie
    - Routes subsequent requests to same server
    - Transparent to application
    
    **IP Hash Affinity:**
    - Hash client IP to determine server
    - Consistent routing for same client
    - No cookies required
    
    **Application-Level Affinity:**
    - Application generates session identifier
    - Load balancer routes based on session ID
    - Most flexible approach
    
    **Trade-offs:**
    - ‚úÖ Enables server-side session storage
    - ‚úÖ Consistent user experience
    - ‚ùå Reduces load distribution efficiency
    - ‚ùå Complicates failover scenarios

=== "üåç Geographic Load Balancing"

    **DNS-Based Geographic Routing:**
    - Route users to nearest data center
    - Reduce latency through proximity
    - Disaster recovery across regions
    
    **Implementation Strategies:**
    - Anycast routing with BGP
    - GeoDNS with location awareness
    - CDN integration for static content
    - Database replication across regions
    
    **Considerations:**
    - Data consistency across regions
    - Compliance and data sovereignty
    - Network connectivity and peering
    - Cost optimization across regions

=== "üìà Auto Scaling Integration"

    **Dynamic Server Management:**
    - Scale servers based on traffic patterns
    - Integrate with cloud auto-scaling groups
    - Graceful server addition and removal
    - Cost optimization through elasticity
    
    **Scaling Triggers:**
    - CPU/memory thresholds
    - Request queue depths
    - Response time degradation
    - Custom application metrics
    
    **Best Practices:**
    - Gradual scaling to avoid thundering herd
    - Warm-up periods for new servers
    - Connection draining for server removal
    - Circuit breakers during scaling events

## üéØ Best Practices & Implementation Guidelines

### Configuration Best Practices

=== "‚öôÔ∏è Load Balancer Configuration"

    **Essential Settings:**
    - Set appropriate timeout values
    - Configure proper health check intervals
    - Enable connection pooling and keep-alive
    - Implement SSL termination for HTTPS
    - Configure proper logging and monitoring
    
    **Security Considerations:**
    - Rate limiting to prevent abuse
    - DDoS protection and mitigation
    - SSL/TLS configuration and cipher suites
    - Access control and IP whitelisting
    - Regular security updates and patches

=== "üèóÔ∏è Architecture Design"

    **High Availability Setup:**
    - Deploy load balancers in active-passive pairs
    - Use multiple availability zones
    - Implement health checks at multiple levels
    - Plan for graceful degradation scenarios
    - Regular disaster recovery testing
    
    **Performance Optimization:**
    - Minimize network hops between components
    - Use connection pooling and multiplexing
    - Implement caching at appropriate layers
    - Optimize SSL/TLS termination
    - Monitor and tune based on real traffic patterns

### Common Pitfalls to Avoid

- **Over-engineering**: Start simple and add complexity as needed
- **Ignoring Health Checks**: Proper health checking is critical
- **Session Affinity Overuse**: Use only when necessary
- **Inadequate Monitoring**: Monitor all layers of the stack
- **Single Point of Failure**: Ensure load balancers are also redundant
- **Poor Failover Testing**: Regularly test failure scenarios

## üîó Related Topics

- **[Horizontal Scaling](../scalability/index.md)** - Scaling strategies and patterns
- **[Service Discovery](../networking/service-discovery.md)** - Dynamic service registration
- **[API Gateway](../networking/api-gateway.md)** - Advanced routing and policies
- **[CDN](../caching/index.md)** - Content delivery and edge caching
- **[Monitoring](../performance/monitoring.md)** - System observability

---

**üí° Key Takeaway:** Effective load balancing is essential for building scalable, reliable systems. Choose algorithms and technologies based on your specific requirements, implement proper health checking, and always plan for failure scenarios.
