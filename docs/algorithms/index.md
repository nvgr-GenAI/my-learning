# Algorithms & Data Structures ğŸ§®

Your comprehensive guide to mastering algorithms and data structures - from fundamentals to advanced concepts. This is your one-stop resource for problem-solving, technical interviews, and competitive programming.

## ğŸ¯ Learning Path

<div class="grid cards" markdown>

- :material-code-array: **Data Structures**

    ---

    Arrays, linked lists, stacks, queues, trees, graphs, sets, hash tables

    [Explore structures â†’](data-structures/index.md)

- :material-sort: **Sorting Algorithms**

    ---

    Quick sort, merge sort, heap sort, and comparison-based sorting

    [Sort it out â†’](sorting/index.md)

- :material-graph: **Graph Algorithms**

    ---

    BFS, DFS, shortest path, MST, topological sort

    [Navigate graphs â†’](graphs/index.md)

- :material-chart-gantt: **Dynamic Programming**

    ---

    Optimization problems, memoization, tabulation

    [Optimize solutions â†’](dp/index.md)

- :material-search: **Searching Algorithms**

    ---

    Binary search, linear search, advanced search techniques

    [Find efficiently â†’](searching/index.md)

- :material-math-integral: **Mathematical Algorithms**

    ---

    Number theory, combinatorics, geometry

    [Crunch numbers â†’](math/index.md)

- :material-algorithm: **Advanced Techniques**

    ---

    Greedy, divide & conquer, backtracking, bit manipulation

    [Master techniques â†’](backtracking/index.md)

- :material-puzzle: **Problem-Solving Patterns**

    ---

    Two pointers, sliding window, fast & slow pointers

    [Learn patterns â†’](problem-solving-patterns.md)

- :material-account-tie: **Interview Preparation**

    ---

    Study plans, strategies, company-specific tips

    [Ace interviews â†’](interview-preparation.md)

</div>

## ğŸ“Š Algorithm Categories Overview

### By Problem Type

| Category | Common Problems | Key Algorithms | Difficulty |
|----------|----------------|----------------|------------|
| **Array/String** | Two Sum, Sliding Window, Palindromes | Two Pointers, Hash Maps | ğŸŸ¢ Easy-Medium |
| **Linked Lists** | Reverse List, Detect Cycle, Merge Lists | Fast/Slow Pointers | ğŸŸ¢ Easy-Medium |
| **Trees/Binary Trees** | Traversals, Path Sum, Lowest Common Ancestor | DFS, BFS, Recursion | ğŸŸ¡ Medium |
| **Binary Search Trees** | Search, Insert, Validate BST | In-order Traversal | ğŸŸ¡ Medium |
| **Graphs** | Connected Components, Shortest Path | BFS, DFS, Dijkstra | ğŸ”´ Medium-Hard |
| **Dynamic Programming** | Fibonacci, Knapsack, Edit Distance | Memoization, Tabulation | ğŸ”´ Hard |
| **Backtracking** | N-Queens, Sudoku, Permutations | Recursive Backtracking | ğŸ”´ Hard |
| **Greedy** | Activity Selection, Huffman Coding | Local Optimization | ğŸŸ¡ Medium |

### By Data Structure

=== "Linear Structures"

    - **Arrays**: Random access, cache-friendly
    - **Linked Lists**: Dynamic size, insertion/deletion
    - **Stacks**: LIFO operations, recursion simulation
    - **Queues**: FIFO operations, BFS, scheduling
    - **Deques**: Double-ended operations

=== "Hierarchical Structures"

    - **Binary Trees**: Hierarchical relationships
    - **Binary Search Trees**: Ordered data, O(log n) operations
    - **Heaps**: Priority operations, min/max finding
    - **Tries**: String processing, prefix matching
    - **Segment Trees**: Range queries and updates

=== "Graph Structures"

    - **Adjacency Matrix**: Dense graphs, O(1) edge lookup
    - **Adjacency List**: Sparse graphs, memory efficient
    - **Weighted Graphs**: Shortest path algorithms
    - **Directed/Undirected**: Different traversal patterns

## â±ï¸ Time & Space Complexity Cheat Sheet

| Complexity | Name | Example Algorithms | Performance |
|------------|------|-------------------|-------------|
| **O(1)** | Constant | Array access, Hash table lookup | ğŸŸ¢ Excellent |
| **O(log n)** | Logarithmic | Binary search, Balanced BST operations | ğŸŸ¢ Excellent |
| **O(n)** | Linear | Linear search, Array traversal | ğŸŸ¡ Good |
| **O(n log n)** | Linearithmic | Merge sort, Heap sort | ğŸŸ¡ Good |
| **O(nÂ²)** | Quadratic | Bubble sort, Selection sort | ğŸ”´ Poor |
| **O(2â¿)** | Exponential | Recursive Fibonacci, Subset generation | ğŸ”´ Terrible |

## ğŸ¯ Quick Start Guide

### For Beginners

1. **Start with [Data Structures](data-structures/index.md)** - Arrays, Linked Lists, Stacks, Queues
2. **Learn [Problem-Solving Patterns](problem-solving-patterns.md)** - Two Pointers, Sliding Window
3. **Practice [Sorting](sorting/index.md)** - Understand comparison-based algorithms
4. **Master [Trees](trees/index.md)** - Binary trees and traversals

### For Interview Preparation

1. **Follow [Interview Strategy](interview-preparation.md)** - Structured study plans
2. **Master [Problem Patterns](problem-solving-patterns.md)** - 80% of interview problems
3. **Practice [Dynamic Programming](dp/index.md)** - Essential for FAANG interviews
4. **Study [System Design](../system-design/index.md)** - For senior roles

### For Competitive Programming

1. **Master [Mathematical Algorithms](math/index.md)** - Number theory, combinatorics
2. **Advanced [Graph Algorithms](graphs/index.md)** - Complex shortest path, flow
3. **Optimize with [Greedy](greedy/index.md)** - Fast decision making
4. **Complex [DP Patterns](dp/index.md)** - Multi-dimensional optimization

## ğŸ“š Essential Learning Resources

### Online Platforms

- **[LeetCode](https://leetcode.com/)** - Interview preparation and practice
- **[HackerRank](https://www.hackerrank.com/)** - Skill assessment and challenges
- **[CodeForces](https://codeforces.com/)** - Competitive programming contests
- **[GeeksforGeeks](https://www.geeksforgeeks.org/)** - Concepts and tutorials

### Recommended Books

- **Introduction to Algorithms (CLRS)** - Comprehensive theoretical foundation
- **Cracking the Coding Interview** - Essential for tech interviews
- **Algorithm Design Manual (Skiena)** - Practical problem-solving approach
- **Elements of Programming Interviews** - Language-specific interview prep

## ğŸš€ Next Steps

Ready to start your algorithms journey? Choose your path:

- **New to algorithms?** Begin with [Data Structures Basics](data-structures/index.md)
- **Preparing for interviews?** Check out [Interview Strategy](interview-preparation.md)
- **Want to see patterns?** Explore [Problem-Solving Patterns](problem-solving-patterns.md)
- **Need specific algorithms?** Browse by category in the sections above

---

**Remember**: Mastering algorithms is a journey, not a destination. Stay consistent, practice regularly, and focus on understanding over memorization. You've got this! ğŸ¯ğŸ’ª

| Complexity | Name | Example Algorithms | Performance |
|------------|------|-------------------|-------------|
| **O(1)** | Constant | Array access, Hash table lookup | ğŸŸ¢ Excellent |
| **O(log n)** | Logarithmic | Binary search, Balanced BST operations | ğŸŸ¢ Excellent |
| **O(n)** | Linear | Linear search, Array traversal | ğŸŸ¡ Good |
| **O(n log n)** | Linearithmic | Merge sort, Heap sort | ğŸŸ¡ Good |
| **O(nÂ²)** | Quadratic | Bubble sort, Selection sort | ğŸ”´ Poor |
| **O(2â¿)** | Exponential | Recursive Fibonacci, Subset generation | ğŸ”´ Terrible |

## ğŸ† Popular Sorting Algorithms

| Algorithm | Time Complexity | Space | Stable | In-Place | Best For |
|-----------|----------------|-------|--------|----------|----------|
| **[Quick Sort](sorting/quick-sort.md)** | O(n log n) avg | O(log n) | âŒ | âœ… | General purpose |
| **[Merge Sort](sorting/merge-sort.md)** | O(n log n) | O(n) | âœ… | âŒ | Stable sorting |
| **[Heap Sort](sorting/heap-sort.md)** | O(n log n) | O(1) | âŒ | âœ… | Guaranteed performance |
| **Insertion Sort** | O(nÂ²) | O(1) | âœ… | âœ… | Small/nearly sorted |
| **Bubble Sort** | O(nÂ²) | O(1) | âœ… | âœ… | Educational |

## ğŸ¯ Essential Problem-Solving Patterns

### Two Pointers

Perfect for array problems, palindromes, and sum problems.

```python
def two_sum_sorted(arr, target):
    left, right = 0, len(arr) - 1
    while left < right:
        current_sum = arr[left] + arr[right]
        if current_sum == target:
            return [left, right]
        elif current_sum < target:
            left += 1
        else:
            right -= 1
    return []
```

### Sliding Window

Ideal for subarray/substring problems with constraints.

```python
def max_sum_subarray(arr, k):
    window_sum = sum(arr[:k])
    max_sum = window_sum
    
    for i in range(k, len(arr)):
        window_sum = window_sum - arr[i - k] + arr[i]
        max_sum = max(max_sum, window_sum)
    
    return max_sum
```

### Fast & Slow Pointers

Great for cycle detection and finding middle elements.

```python
def has_cycle(head):
    slow = fast = head
    while fast and fast.next:
        slow = slow.next
        fast = fast.next.next
        if slow == fast:
            return True
    return False
```

## ğŸ“š Learning Resources

### Essential Platforms

| Platform | Focus | Difficulty | Best For |
|----------|-------|------------|----------|
| **LeetCode** | Interview prep | Easy-Hard | FAANG interviews |
| **HackerRank** | Programming challenges | Easy-Expert | Skill assessment |
| **CodeForces** | Competitive programming | Div2-Div1 | Contest training |
| **GeeksforGeeks** | Concepts & examples | Easy-Hard | Learning fundamentals |

### Must-Read Books

- **Introduction to Algorithms (CLRS)** - Comprehensive theoretical foundation
- **Cracking the Coding Interview** - Essential for tech interviews
- **Algorithm Design Manual (Skiena)** - Practical problem-solving approach
- **Elements of Programming Interviews** - Language-specific interview prep

## ğŸ—“ï¸ 12-Week Study Plan

| Week | Focus | Topics | Practice Problems |
|------|-------|--------|------------------|
| **1-2** | Arrays & Strings | Two pointers, sliding window | Two Sum, Longest Substring |
| **3-4** | Linked Lists | Manipulation, cycle detection | Reverse List, Merge Lists |
| **5-6** | Trees & BSTs | Traversals, construction | Inorder Traversal, Path Sum |
| **7-8** | Graphs | BFS, DFS, shortest path | Number of Islands, Course Schedule |
| **9-10** | Dynamic Programming | Basic patterns | Climbing Stairs, Coin Change |
| **11-12** | Review & Practice | Mock interviews | Mixed hard problems |

## ğŸ¯ Interview Preparation Strategy

### Problem Frequency by Category

1. **Arrays & Strings** (35% of interviews)
2. **Trees & Graphs** (25% of interviews)
3. **Dynamic Programming** (20% of interviews)
4. **Linked Lists** (15% of interviews)
5. **Others** (5% of interviews)

### Daily Practice Routine

!!! tip "Recommended Schedule"

    - **Warm-up**: 1 easy problem (10-15 min)
    - **Main**: 1-2 medium problems (30-45 min each)
    - **Challenge**: 1 hard problem (weekly)
    - **Review**: Revisit problems from 1 week ago

### Problem-Solving Framework

!!! note "Step-by-Step Approach"

    1. **Understand**: Read carefully, identify constraints
    2. **Plan**: Think of approach, consider edge cases
    3. **Code**: Implement solution step by step
    4. **Test**: Verify with examples, check edge cases
    5. **Optimize**: Analyze complexity, improve if possible
    6. **Reflect**: Note patterns and techniques used

## ğŸš€ Next Steps

Ready to dive deeper? Choose your path:

=== "Beginner"

    Start with fundamentals:
    
    1. [Data Structures Basics](data-structures.md)
    2. [Simple Sorting Algorithms](sorting.md)
    3. [Backtracking Problems](backtracking/index.md)

=== "Intermediate"

    Build advanced skills:
    
    1. [Graph Algorithms](graphs.md)
    2. [Dynamic Programming](dp.md)
    3. [Advanced Sorting](sorting/quick-sort.md)

=== "Advanced"

    Master complex topics:
    
    1. [Greedy Algorithms](greedy/index.md)
    2. [Mathematical Algorithms](math.md)
    3. [Divide & Conquer Patterns](divide-conquer/index.md)

---

**Master algorithms, ace interviews, build amazing systems! ğŸš€ğŸ’»**

Understanding algorithmic complexity is fundamental to writing efficient code.

### Big O Notation Cheat Sheet

| Complexity | Name | Example Algorithms | Performance |
|------------|------|-------------------|-------------|
| **O(1)** | Constant | Array access, Hash table lookup | ğŸŸ¢ Excellent |
| **O(log n)** | Logarithmic | Binary search, Balanced BST operations | ğŸŸ¢ Excellent |
| **O(n)** | Linear | Linear search, Array traversal | ğŸŸ¡ Good |
| **O(n log n)** | Linearithmic | Merge sort, Heap sort, Fast Fourier Transform | ğŸŸ¡ Good |
| **O(nÂ²)** | Quadratic | Bubble sort, Selection sort, Nested loops | ğŸ”´ Poor |
| **O(nÂ³)** | Cubic | Floyd-Warshall, Matrix multiplication | ğŸ”´ Very Poor |
| **O(2â¿)** | Exponential | Recursive Fibonacci, Subset generation | ğŸ”´ Terrible |
| **O(n!)** | Factorial | Permutation generation, Traveling salesman (brute force) | ğŸ”´ Terrible |

### Complexity Growth Visualization

```python
import matplotlib.pyplot as plt
import numpy as np

# Complexity growth comparison
def plot_complexity_growth():
    n = np.linspace(1, 100, 100)
    
    plt.figure(figsize=(12, 8))
    
    complexities = {
        'O(1)': np.ones_like(n),
        'O(log n)': np.log2(n),
        'O(n)': n,
        'O(n log n)': n * np.log2(n),
        'O(nÂ²)': n**2,
    }
    
    for name, values in complexities.items():
        plt.plot(n, values, label=name, linewidth=2)
    
    plt.xlabel('Input Size (n)', fontsize=12)
    plt.ylabel('Operations', fontsize=12)
    plt.title('Algorithm Complexity Growth Comparison', fontsize=14)
    plt.legend(fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.yscale('log')
    plt.show()

# Call this function to see the complexity comparison
# plot_complexity_growth()
```

## ğŸ† Problem-Solving Strategies

### 1. Understand the Problem

- Read the problem statement carefully
- Identify inputs, outputs, and constraints
- Work through examples manually
- Ask clarifying questions

### 2. Choose the Right Approach

- **Brute Force**: Start simple, then optimize
- **Divide & Conquer**: Break into smaller subproblems
- **Greedy**: Make locally optimal choices
- **Dynamic Programming**: Overlapping subproblems
- **Backtracking**: Explore all possibilities systematically

### 3. Implement and Test

- Write clean, readable code
- Handle edge cases
- Test with various inputs
- Optimize after correctness

### 4. Common Patterns to Recognize

| Pattern | When to Use | Examples |
|---------|-------------|----------|
| **Two Pointers** | Sorted arrays, palindromes | Two Sum, Container with Most Water |
| **Sliding Window** | Subarray/substring problems | Longest Substring, Max Sum Subarray |
| **Hash Maps** | Frequency counting, lookups | Anagram check, First non-repeating char |
| **BFS/DFS** | Tree/graph traversal | Level order, Connected components |
| **Binary Search** | Sorted data, search space | Find element, Search in rotated array |

## ğŸ“š Essential Topics by Category

### ğŸ”¢ **Arrays & Strings**

- Two pointers technique
- Sliding window
- Prefix sums
- Hash table applications
- String matching algorithms

### ğŸ”— **Linked Lists**

- Singly/doubly linked lists
- Fast and slow pointers
- Cycle detection
- Merging and sorting

### ğŸŒ³ **Trees & Binary Trees**

- Tree traversals (preorder, inorder, postorder)
- Binary search trees
- Balanced trees (AVL, Red-Black)
- Segment trees, Fenwick trees

### ğŸ“Š **Graphs**

- Graph representations
- BFS and DFS traversals
- Shortest path algorithms
- Minimum spanning trees
- Topological sorting

### ğŸ¯ **Dynamic Programming**

- 1D and 2D DP problems
- Knapsack variations
- Longest common subsequence
- Edit distance
- Matrix chain multiplication

### âš¡ **Advanced Topics**

- Union-Find (Disjoint Set)
- Trie data structure
- Heap and priority queues
- Bit manipulation
- String algorithms (KMP, Rabin-Karp)

## ğŸ¯ Interview Preparation Roadmap

### Phase 1: Foundations (2-3 weeks)

1. **Arrays & Strings**: Two pointers, sliding window
2. **Linked Lists**: Basic operations, cycle detection
3. **Stacks & Queues**: Implementation and applications
4. **Recursion**: Base cases, recursive thinking

### Phase 2: Core Structures (3-4 weeks)

1. **Binary Trees**: Traversals, basic operations
2. **Binary Search**: Template and variations
3. **Hash Tables**: Design and applications
4. **Sorting**: Understanding different algorithms

### Phase 3: Advanced Topics (4-5 weeks)

1. **Graphs**: BFS, DFS, shortest paths
2. **Dynamic Programming**: Classic problems
3. **Backtracking**: Systematic exploration
4. **Greedy Algorithms**: Optimization problems

### Phase 4: Mastery (2-3 weeks)

1. **System Design**: Scalability concepts
2. **Mock Interviews**: Practice under pressure
3. **Company-specific**: Research target companies
4. **Review**: Solidify weak areas

## ğŸ”§ Practice Resources

### Online Platforms

- **[LeetCode](https://leetcode.com/)**: Comprehensive problem set
- **[HackerRank](https://www.hackerrank.com/)**: Skill-based challenges
- **[CodeForces](https://codeforces.com/)**: Competitive programming
- **[GeeksforGeeks](https://www.geeksforgeeks.org/)**: Tutorials and problems

### Books

- **"Cracking the Coding Interview"** by Gayle McDowell
- **"Elements of Programming Interviews"** by Aziz, Lee, Prakash
- **"Algorithm Design Manual"** by Steven Skiena
- **"Introduction to Algorithms"** by CLRS

### YouTube Channels

- **Abdul Bari**: Algorithm explanations
- **Back To Back SWE**: Interview-focused content
- **Tushar Roy**: Dynamic programming
- **William Fiset**: Graph algorithms

## ğŸ“ˆ Progress Tracking

### Problem Categories Checklist

=== "Easy (Foundation)"
    - [ ] Two Sum
    - [ ] Valid Parentheses
    - [ ] Merge Two Sorted Lists
    - [ ] Maximum Subarray
    - [ ] Best Time to Buy Stock
    - [ ] Valid Palindrome
    - [ ] Binary Tree Inorder Traversal
    - [ ] Symmetric Tree
    - [ ] Maximum Depth of Binary Tree
    - [ ] Single Number

=== "Medium (Building Skills)"
    - [ ] Add Two Numbers
    - [ ] Longest Substring Without Repeating Characters
    - [ ] Container With Most Water
    - [ ] 3Sum
    - [ ] Group Anagrams
    - [ ] Validate Binary Search Tree
    - [ ] Binary Tree Level Order Traversal
    - [ ] Construct Binary Tree from Traversals
    - [ ] Kth Largest Element in Array
    - [ ] Word Search

=== "Hard (Mastery)"
    - [ ] Median of Two Sorted Arrays
    - [ ] Regular Expression Matching
    - [ ] Merge k Sorted Lists
    - [ ] Reverse Nodes in k-Group
    - [ ] Substring with Concatenation of All Words
    - [ ] Edit Distance
    - [ ] Largest Rectangle in Histogram
    - [ ] Maximal Rectangle
    - [ ] Word Ladder II
    - [ ] Palindrome Partitioning II

### Weekly Goals Template

```markdown
## Week X Goals
- **Topic Focus**: [e.g., Dynamic Programming]
- **Problems to Solve**: 15-20
- **New Concepts**: [e.g., Knapsack pattern]
- **Review**: Previous week's difficult problems
- **Mock Interview**: 1 session

### Daily Breakdown
- Monday: 3-4 easy problems
- Tuesday: 2-3 medium problems
- Wednesday: 1 hard problem + review
- Thursday: 2-3 medium problems
- Friday: Mixed difficulty + mock interview
- Weekend: Review and solidify concepts
```

## ğŸ“ Success Tips

### For Technical Interviews

1. **Think Out Loud**: Communicate your thought process
2. **Start Simple**: Begin with brute force, then optimize
3. **Test Your Code**: Walk through examples
4. **Handle Edge Cases**: Consider null inputs, empty arrays
5. **Ask Questions**: Clarify requirements and constraints

### For Competitive Programming

1. **Speed Matters**: Practice typing and common patterns
2. **Template Ready**: Have pre-written code snippets
3. **Read Problems Carefully**: Understand constraints
4. **Time Management**: Don't get stuck on one problem
5. **Learn from Others**: Study editorial solutions

### For Long-term Growth

1. **Consistent Practice**: Better than intensive bursts
2. **Understand, Don't Memorize**: Focus on patterns
3. **Teach Others**: Explaining helps solidify understanding
4. **Stay Updated**: Follow algorithm research and new techniques
5. **Build Projects**: Apply algorithms in real applications

---

## ğŸš€ Ready to Start?

Choose your learning path based on your goals:

- **Job Interview Prep**: Start with [Data Structures](data-structures.md) â†’ [Sorting](sorting.md) â†’ [Dynamic Programming](dp.md)
- **Competitive Programming**: Begin with [Mathematical Algorithms](math.md) â†’ [Greedy Algorithms](greedy/index.md) â†’ [Graph Algorithms](graphs.md)
- **Academic Study**: Follow the structured path: [Data Structures](data-structures.md) â†’ [Sorting](sorting.md) â†’ [Graphs](graphs.md) â†’ [DP](dp.md) â†’ [Backtracking](backtracking/index.md)

Remember: The key to mastering algorithms is consistent practice and understanding the underlying patterns. Start with the basics and gradually work your way up to more complex problems.

*Happy coding! ğŸ¯*

Understanding algorithmic complexity is fundamental to writing efficient code.

### Big O Notation Cheat Sheet

| Complexity | Name | Example Algorithms | Performance |
|------------|------|-------------------|-------------|
| **O(1)** | Constant | Array access, Hash table lookup | ğŸŸ¢ Excellent |
| **O(log n)** | Logarithmic | Binary search, Balanced BST operations | ğŸŸ¢ Excellent |
| **O(n)** | Linear | Linear search, Array traversal | ğŸŸ¡ Good |
| **O(n log n)** | Linearithmic | Merge sort, Heap sort, Fast Fourier Transform | ğŸŸ¡ Good |
| **O(nÂ²)** | Quadratic | Bubble sort, Selection sort, Nested loops | ğŸ”´ Poor |
| **O(nÂ³)** | Cubic | Floyd-Warshall, Matrix multiplication | ğŸ”´ Very Poor |
| **O(2â¿)** | Exponential | Recursive Fibonacci, Subset generation | ğŸ”´ Terrible |
| **O(n!)** | Factorial | Permutation generation, Traveling salesman (brute force) | ğŸ”´ Terrible |

### Visual Complexity Comparison

```python
import matplotlib.pyplot as plt
import numpy as np

# Complexity growth visualization
n = np.linspace(1, 100, 100)
complexities = {
    'O(1)': np.ones_like(n),
    'O(log n)': np.log2(n),
    'O(n)': n,
    'O(n log n)': n * np.log2(n),
    'O(nÂ²)': n**2,
    'O(2â¿)': 2**n[:20]  # Limited to prevent overflow
}

# Plot complexity curves
for name, values in complexities.items():
    if name == 'O(2â¿)':
        plt.plot(n[:20], values, label=name)
    else:
        plt.plot(n, values, label=name)

plt.xlabel('Input Size (n)')
plt.ylabel('Operations')
plt.title('Algorithm Complexity Growth')
plt.legend()
plt.yscale('log')
plt.grid(True)
plt.show()
```

## ğŸ”§ Core Data Structures Implementation

### Dynamic Array (Python List Alternative)

```python
class DynamicArray:
    """
    A resizable array implementation with amortized O(1) append.
    Demonstrates capacity doubling strategy.
    """
    def __init__(self, capacity=2):
        self.capacity = capacity
        self.size = 0
        self.data = [None] * self.capacity
    
    def __len__(self):
        return self.size
    
    def __getitem__(self, index):
        if not 0 <= index < self.size:
            raise IndexError("Index out of range")
        return self.data[index]
    
    def __setitem__(self, index, value):
        if not 0 <= index < self.size:
            raise IndexError("Index out of range")
        self.data[index] = value
    
    def _resize(self, new_capacity):
        """Double the capacity when needed."""
        old_data = self.data
        self.capacity = new_capacity
        self.data = [None] * self.capacity
        
        for i in range(self.size):
            self.data[i] = old_data[i]
    
    def append(self, item):
        """Add item to end. Amortized O(1) time."""
        if self.size >= self.capacity:
            self._resize(2 * self.capacity)
        
        self.data[self.size] = item
        self.size += 1
    
    def insert(self, index, item):
        """Insert item at index. O(n) time."""
        if not 0 <= index <= self.size:
            raise IndexError("Index out of range")
        
        if self.size >= self.capacity:
            self._resize(2 * self.capacity)
        
        # Shift elements to the right
        for i in range(self.size, index, -1):
            self.data[i] = self.data[i-1]
        
        self.data[index] = item
        self.size += 1
    
    def pop(self, index=-1):
        """Remove and return item at index. O(n) time."""
        if self.size == 0:
            raise IndexError("Pop from empty array")
        
        if index < 0:
            index += self.size
        
        if not 0 <= index < self.size:
            raise IndexError("Index out of range")
        
        item = self.data[index]
        
        # Shift elements to the left
        for i in range(index, self.size - 1):
            self.data[i] = self.data[i + 1]
        
        self.size -= 1
        
        # Shrink if necessary (optional optimization)
        if self.size <= self.capacity // 4:
            self._resize(self.capacity // 2)
        
        return item

# Usage example
arr = DynamicArray()
for i in range(10):
    arr.append(i)

print(f"Array: {[arr[i] for i in range(len(arr))]}")
print(f"Length: {len(arr)}, Capacity: {arr.capacity}")
```

### Advanced Linked List with Multiple Operations

```python
class ListNode:
    """Node for doubly linked list."""
    def __init__(self, val=0, prev=None, next=None):
        self.val = val
        self.prev = prev
        self.next = next

class DoublyLinkedList:
    """
    Doubly linked list with O(1) insertion/deletion at both ends.
    Useful for implementing deques, LRU cache, etc.
    """
    def __init__(self):
        # Sentinel nodes to simplify edge cases
        self.head = ListNode()
        self.tail = ListNode()
        self.head.next = self.tail
        self.tail.prev = self.head
        self.size = 0
    
    def _add_node(self, node, prev_node):
        """Add node after prev_node."""
        next_node = prev_node.next
        
        prev_node.next = node
        node.prev = prev_node
        node.next = next_node
        next_node.prev = node
        
        self.size += 1
    
    def _remove_node(self, node):
        """Remove given node."""
        prev_node = node.prev
        next_node = node.next
        
        prev_node.next = next_node
        next_node.prev = prev_node
        
        self.size -= 1
    
    def add_first(self, val):
        """Add to front. O(1) time."""
        new_node = ListNode(val)
        self._add_node(new_node, self.head)
    
    def add_last(self, val):
        """Add to back. O(1) time."""
        new_node = ListNode(val)
        self._add_node(new_node, self.tail.prev)
    
    def remove_first(self):
        """Remove from front. O(1) time."""
        if self.size == 0:
            raise IndexError("Remove from empty list")
        
        first_node = self.head.next
        self._remove_node(first_node)
        return first_node.val
    
    def remove_last(self):
        """Remove from back. O(1) time."""
        if self.size == 0:
            raise IndexError("Remove from empty list")
        
        last_node = self.tail.prev
        self._remove_node(last_node)
        return last_node.val
    
    def find_and_remove(self, val):
        """Find and remove first occurrence. O(n) time."""
        current = self.head.next
        while current != self.tail:
            if current.val == val:
                self._remove_node(current)
                return True
            current = current.next
        return False
    
    def to_list(self):
        """Convert to Python list for easy viewing."""
        result = []
        current = self.head.next
        while current != self.tail:
            result.append(current.val)
            current = current.next
        return result
    
    def __len__(self):
        return self.size

# Usage example
dll = DoublyLinkedList()
for i in range(5):
    dll.add_last(i)
    dll.add_first(-i)

print(f"List: {dll.to_list()}")
print(f"Remove first: {dll.remove_first()}")
print(f"Remove last: {dll.remove_last()}")
print(f"Final list: {dll.to_list()}")
```

### Binary Search Tree with Rotations

```python
class TreeNode:
    def __init__(self, val=0, left=None, right=None):
        self.val = val
        self.left = left
        self.right = right
        self.height = 1  # For AVL tree balancing

class BinarySearchTree:
    """
    Enhanced BST with various operations and tree traversals.
    Includes height balancing for AVL tree functionality.
    """
    def __init__(self):
        self.root = None
    
    def _get_height(self, node):
        """Get height of node (0 for None)."""
        return node.height if node else 0
    
    def _update_height(self, node):
        """Update height based on children."""
        if node:
            node.height = 1 + max(self._get_height(node.left), 
                                 self._get_height(node.right))
    
    def _get_balance(self, node):
        """Get balance factor for AVL tree."""
        return self._get_height(node.left) - self._get_height(node.right) if node else 0
    
    def _rotate_right(self, y):
        """Right rotation for AVL balancing."""
        x = y.left
        T2 = x.right
        
        # Perform rotation
        x.right = y
        y.left = T2
        
        # Update heights
        self._update_height(y)
        self._update_height(x)
        
        return x
    
    def _rotate_left(self, x):
        """Left rotation for AVL balancing."""
        y = x.right
        T2 = y.left
        
        # Perform rotation
        y.left = x
        x.right = T2
        
        # Update heights
        self._update_height(x)
        self._update_height(y)
        
        return y
    
    def insert(self, val):
        """Insert value maintaining BST property and AVL balance."""
        self.root = self._insert_recursive(self.root, val)
    
    def _insert_recursive(self, node, val):
        # Standard BST insertion
        if not node:
            return TreeNode(val)
        
        if val < node.val:
            node.left = self._insert_recursive(node.left, val)
        elif val > node.val:
            node.right = self._insert_recursive(node.right, val)
        else:
            return node  # No duplicates
        
        # Update height
        self._update_height(node)
        
        # Check balance and rotate if needed (AVL property)
        balance = self._get_balance(node)
        
        # Left heavy
        if balance > 1:
            if val < node.left.val:  # Left-Left case
                return self._rotate_right(node)
            else:  # Left-Right case
                node.left = self._rotate_left(node.left)
                return self._rotate_right(node)
        
        # Right heavy
        if balance < -1:
            if val > node.right.val:  # Right-Right case
                return self._rotate_left(node)
            else:  # Right-Left case
                node.right = self._rotate_right(node.right)
                return self._rotate_left(node)
        
        return node
    
    def search(self, val):
        """Search for value. O(log n) average, O(n) worst."""
        return self._search_recursive(self.root, val)
    
    def _search_recursive(self, node, val):
        if not node or node.val == val:
            return node
        
        if val < node.val:
            return self._search_recursive(node.left, val)
        return self._search_recursive(node.right, val)
    
    def delete(self, val):
        """Delete value maintaining BST property."""
        self.root = self._delete_recursive(self.root, val)
    
    def _delete_recursive(self, node, val):
        if not node:
            return node
        
        if val < node.val:
            node.left = self._delete_recursive(node.left, val)
        elif val > node.val:
            node.right = self._delete_recursive(node.right, val)
        else:
            # Node to delete found
            if not node.left:
                return node.right
            elif not node.right:
                return node.left
            else:
                # Node has two children - find inorder successor
                successor = self._find_min(node.right)
                node.val = successor.val
                node.right = self._delete_recursive(node.right, successor.val)
        
        return node
    
    def _find_min(self, node):
        """Find minimum value node in subtree."""
        while node.left:
            node = node.left
        return node
    
    def inorder_traversal(self):
        """Return inorder traversal (sorted order for BST)."""
        result = []
        self._inorder_helper(self.root, result)
        return result
    
    def _inorder_helper(self, node, result):
        if node:
            self._inorder_helper(node.left, result)
            result.append(node.val)
            self._inorder_helper(node.right, result)
    
    def level_order_traversal(self):
        """Return level-order traversal (BFS)."""
        if not self.root:
            return []
        
        result = []
        queue = [self.root]
        
        while queue:
            level_size = len(queue)
            level = []
            
            for _ in range(level_size):
                node = queue.pop(0)
                level.append(node.val)
                
                if node.left:
                    queue.append(node.left)
                if node.right:
                    queue.append(node.right)
            
            result.append(level)
        
        return result
    
    def is_balanced(self):
        """Check if tree is height-balanced (AVL property)."""
        return self._is_balanced_helper(self.root)[0]
    
    def _is_balanced_helper(self, node):
        """Returns (is_balanced, height)."""
        if not node:
            return True, 0
        
        left_balanced, left_height = self._is_balanced_helper(node.left)
        right_balanced, right_height = self._is_balanced_helper(node.right)
        
        balanced = (left_balanced and right_balanced and 
                   abs(left_height - right_height) <= 1)
        height = 1 + max(left_height, right_height)
        
        return balanced, height

# Usage example
bst = BinarySearchTree()
values = [50, 30, 70, 20, 40, 60, 80, 10, 25, 35, 45]

for val in values:
    bst.insert(val)

print(f"Inorder traversal: {bst.inorder_traversal()}")
print(f"Level order traversal: {bst.level_order_traversal()}")
print(f"Is balanced: {bst.is_balanced()}")
print(f"Search 35: {bst.search(35) is not None}")

bst.delete(30)
print(f"After deleting 30: {bst.inorder_traversal()}")
```

## ğŸ¯ Problem-Solving Patterns & Techniques

Master these patterns to solve 80% of coding interview problems efficiently.

### Two Pointers Technique

**Use Cases**: Array problems, string palindromes, sum problems
**Time**: O(n), **Space**: O(1)

```python
def two_sum_sorted(arr, target):
    """Find two numbers that sum to target in sorted array."""
    left, right = 0, len(arr) - 1
    
    while left < right:
        current_sum = arr[left] + arr[right]
        if current_sum == target:
            return [left, right]
        elif current_sum < target:
            left += 1
        else:
            right -= 1
    
    return []

def is_palindrome(s):
    """Check if string is palindrome ignoring case and non-alphanumeric."""
    left, right = 0, len(s) - 1
    
    while left < right:
        while left < right and not s[left].isalnum():
            left += 1
        while left < right and not s[right].isalnum():
            right -= 1
        
        if s[left].lower() != s[right].lower():
            return False
        
        left += 1
        right -= 1
    
    return True

def remove_duplicates(arr):
    """Remove duplicates from sorted array in-place."""
    if not arr:
        return 0
    
    write_index = 1
    for read_index in range(1, len(arr)):
        if arr[read_index] != arr[read_index - 1]:
            arr[write_index] = arr[read_index]
            write_index += 1
    
    return write_index
```

### Sliding Window Pattern

**Use Cases**: Subarray problems, string problems with constraints
**Time**: O(n), **Space**: O(1) or O(k)

```python
def max_sum_subarray(arr, k):
    """Find maximum sum of subarray of size k."""
    if len(arr) < k:
        return None
    
    # Calculate sum of first window
    window_sum = sum(arr[:k])
    max_sum = window_sum
    
    # Slide the window
    for i in range(k, len(arr)):
        window_sum = window_sum - arr[i - k] + arr[i]
        max_sum = max(max_sum, window_sum)
    
    return max_sum

def longest_substring_k_distinct(s, k):
    """Find longest substring with at most k distinct characters."""
    if not s or k == 0:
        return 0
    
    char_count = {}
    left = 0
    max_length = 0
    
    for right in range(len(s)):
        # Expand window
        char_count[s[right]] = char_count.get(s[right], 0) + 1
        
        # Contract window if needed
        while len(char_count) > k:
            char_count[s[left]] -= 1
            if char_count[s[left]] == 0:
                del char_count[s[left]]
            left += 1
        
        max_length = max(max_length, right - left + 1)
    
    return max_length

def min_window_substring(s, t):
    """Find minimum window substring containing all characters of t."""
    if not s or not t:
        return ""
    
    # Count characters in t
    t_count = {}
    for char in t:
        t_count[char] = t_count.get(char, 0) + 1
    
    left = 0
    min_len = float('inf')
    min_start = 0
    required = len(t_count)
    formed = 0
    window_counts = {}
    
    for right in range(len(s)):
        char = s[right]
        window_counts[char] = window_counts.get(char, 0) + 1
        
        if char in t_count and window_counts[char] == t_count[char]:
            formed += 1
        
        # Try to contract window
        while left <= right and formed == required:
            if right - left + 1 < min_len:
                min_len = right - left + 1
                min_start = left
            
            char = s[left]
            window_counts[char] -= 1
            if char in t_count and window_counts[char] < t_count[char]:
                formed -= 1
            
            left += 1
    
    return "" if min_len == float('inf') else s[min_start:min_start + min_len]
```

### Fast & Slow Pointers (Floyd's Algorithm)

**Use Cases**: Cycle detection, finding middle element, palindrome checking
**Time**: O(n), **Space**: O(1)

```python
def has_cycle(head):
    """Detect cycle in linked list."""
    if not head or not head.next:
        return False
    
    slow = fast = head
    
    while fast and fast.next:
        slow = slow.next
        fast = fast.next.next
        
        if slow == fast:
            return True
    
    return False

def find_cycle_start(head):
    """Find the start of cycle in linked list."""
    if not head or not head.next:
        return None
    
    # Phase 1: Detect cycle
    slow = fast = head
    while fast and fast.next:
        slow = slow.next
        fast = fast.next.next
        if slow == fast:
            break
    else:
        return None  # No cycle
    
    # Phase 2: Find cycle start
    slow = head
    while slow != fast:
        slow = slow.next
        fast = fast.next
    
    return slow

def find_middle(head):
    """Find middle node of linked list."""
    slow = fast = head
    
    while fast and fast.next:
        slow = slow.next
        fast = fast.next.next
    
    return slow

def is_happy_number(n):
    """Check if number is happy (sum of squares of digits eventually becomes 1)."""
    def get_sum_of_squares(num):
        total = 0
        while num > 0:
            digit = num % 10
            total += digit * digit
            num //= 10
        return total
    
    slow = fast = n
    
    while True:
        slow = get_sum_of_squares(slow)
        fast = get_sum_of_squares(get_sum_of_squares(fast))
        
        if fast == 1:
            return True
        if slow == fast:
            return False
```

### Merge Intervals Pattern

**Use Cases**: Overlapping intervals, scheduling problems
**Time**: O(n log n), **Space**: O(n)

```python
def merge_intervals(intervals):
    """Merge overlapping intervals."""
    if not intervals:
        return []
    
    # Sort by start time
    intervals.sort(key=lambda x: x[0])
    merged = [intervals[0]]
    
    for current in intervals[1:]:
        last_merged = merged[-1]
        
        if current[0] <= last_merged[1]:  # Overlap
            last_merged[1] = max(last_merged[1], current[1])
        else:
            merged.append(current)
    
    return merged

def insert_interval(intervals, new_interval):
    """Insert new interval and merge if necessary."""
    result = []
    i = 0
    
    # Add all intervals that end before new interval starts
    while i < len(intervals) and intervals[i][1] < new_interval[0]:
        result.append(intervals[i])
        i += 1
    
    # Merge overlapping intervals
    while i < len(intervals) and intervals[i][0] <= new_interval[1]:
        new_interval[0] = min(new_interval[0], intervals[i][0])
        new_interval[1] = max(new_interval[1], intervals[i][1])
        i += 1
    
    result.append(new_interval)
    
    # Add remaining intervals
    while i < len(intervals):
        result.append(intervals[i])
        i += 1
    
    return result

def can_attend_meetings(intervals):
    """Check if person can attend all meetings (no overlaps)."""
    intervals.sort(key=lambda x: x[0])
    
    for i in range(1, len(intervals)):
        if intervals[i][0] < intervals[i-1][1]:
            return False
    
    return True

def min_meeting_rooms(intervals):
    """Find minimum number of meeting rooms required."""
    if not intervals:
        return 0
    
    import heapq
    
    # Sort by start time
    intervals.sort(key=lambda x: x[0])
    
    # Min heap to track end times
    heap = []
    
    for interval in intervals:
        start, end = interval
        
        # Remove meetings that have ended
        while heap and heap[0] <= start:
            heapq.heappop(heap)
        
        # Add current meeting end time
        heapq.heappush(heap, end)
    
    return len(heap)
```

## ğŸ” Advanced Algorithm Categories

### Graph Algorithms Comprehensive Guide

```python
from collections import defaultdict, deque
import heapq

class Graph:
    """Comprehensive graph implementation with multiple algorithms."""
    
    def __init__(self, directed=False):
        self.graph = defaultdict(list)
        self.directed = directed
        self.weights = {}  # For weighted graphs
    
    def add_edge(self, u, v, weight=1):
        """Add edge to graph."""
        self.graph[u].append(v)
        self.weights[(u, v)] = weight
        
        if not self.directed:
            self.graph[v].append(u)
            self.weights[(v, u)] = weight
    
    def bfs(self, start):
        """Breadth-First Search traversal."""
        visited = set()
        queue = deque([start])
        result = []
        
        while queue:
            vertex = queue.popleft()
            if vertex not in visited:
                visited.add(vertex)
                result.append(vertex)
                
                for neighbor in self.graph[vertex]:
                    if neighbor not in visited:
                        queue.append(neighbor)
        
        return result
    
    def dfs(self, start):
        """Depth-First Search traversal."""
        visited = set()
        result = []
        
        def dfs_recursive(vertex):
            visited.add(vertex)
            result.append(vertex)
            
            for neighbor in self.graph[vertex]:
                if neighbor not in visited:
                    dfs_recursive(neighbor)
        
        dfs_recursive(start)
        return result
    
    def shortest_path_dijkstra(self, start, end):
        """Find shortest path using Dijkstra's algorithm."""
        distances = defaultdict(lambda: float('inf'))
        distances[start] = 0
        previous = {}
        heap = [(0, start)]
        visited = set()
        
        while heap:
            current_distance, current = heapq.heappop(heap)
            
            if current in visited:
                continue
            
            visited.add(current)
            
            if current == end:
                # Reconstruct path
                path = []
                while current in previous:
                    path.append(current)
                    current = previous[current]
                path.append(start)
                return list(reversed(path)), distances[end]
            
            for neighbor in self.graph[current]:
                distance = current_distance + self.weights.get((current, neighbor), 1)
                
                if distance < distances[neighbor]:
                    distances[neighbor] = distance
                    previous[neighbor] = current
                    heapq.heappush(heap, (distance, neighbor))
        
        return None, float('inf')
    
    def detect_cycle(self):
        """Detect cycle in graph."""
        if not self.directed:
            return self._detect_cycle_undirected()
        else:
            return self._detect_cycle_directed()
    
    def _detect_cycle_undirected(self):
        """Detect cycle in undirected graph using DFS."""
        visited = set()
        
        def dfs(vertex, parent):
            visited.add(vertex)
            
            for neighbor in self.graph[vertex]:
                if neighbor not in visited:
                    if dfs(neighbor, vertex):
                        return True
                elif neighbor != parent:
                    return True
            
            return False
        
        for vertex in self.graph:
            if vertex not in visited:
                if dfs(vertex, -1):
                    return True
        
        return False
    
    def _detect_cycle_directed(self):
        """Detect cycle in directed graph using DFS."""
        WHITE, GRAY, BLACK = 0, 1, 2
        color = defaultdict(int)
        
        def dfs(vertex):
            if color[vertex] == GRAY:
                return True  # Back edge found
            if color[vertex] == BLACK:
                return False
            
            color[vertex] = GRAY
            
            for neighbor in self.graph[vertex]:
                if dfs(neighbor):
                    return True
            
            color[vertex] = BLACK
            return False
        
        for vertex in self.graph:
            if color[vertex] == WHITE:
                if dfs(vertex):
                    return True
        
        return False
    
    def topological_sort(self):
        """Topological sort for DAG."""
        if not self.directed:
            raise ValueError("Topological sort only applies to directed graphs")
        
        in_degree = defaultdict(int)
        
        # Calculate in-degrees
        for vertex in self.graph:
            for neighbor in self.graph[vertex]:
                in_degree[neighbor] += 1
        
        # Find vertices with no incoming edges
        queue = deque([v for v in self.graph if in_degree[v] == 0])
        result = []
        
        while queue:
            vertex = queue.popleft()
            result.append(vertex)
            
            for neighbor in self.graph[vertex]:
                in_degree[neighbor] -= 1
                if in_degree[neighbor] == 0:
                    queue.append(neighbor)
        
        if len(result) != len(self.graph):
            raise ValueError("Graph contains a cycle")
        
        return result
    
    def minimum_spanning_tree_kruskal(self):
        """Find MST using Kruskal's algorithm."""
        class UnionFind:
            def __init__(self, vertices):
                self.parent = {v: v for v in vertices}
                self.rank = {v: 0 for v in vertices}
            
            def find(self, x):
                if self.parent[x] != x:
                    self.parent[x] = self.find(self.parent[x])
                return self.parent[x]
            
            def union(self, x, y):
                px, py = self.find(x), self.find(y)
                if px == py:
                    return False
                
                if self.rank[px] < self.rank[py]:
                    self.parent[px] = py
                elif self.rank[px] > self.rank[py]:
                    self.parent[py] = px
                else:
                    self.parent[py] = px
                    self.rank[px] += 1
                
                return True
        
        # Get all edges
        edges = []
        for u in self.graph:
            for v in self.graph[u]:
                weight = self.weights.get((u, v), 1)
                edges.append((weight, u, v))
        
        # Sort edges by weight
        edges.sort()
        
        # Get all vertices
        vertices = set()
        for u in self.graph:
            vertices.add(u)
            for v in self.graph[u]:
                vertices.add(v)
        
        uf = UnionFind(vertices)
        mst = []
        total_weight = 0
        
        for weight, u, v in edges:
            if uf.union(u, v):
                mst.append((u, v, weight))
                total_weight += weight
        
        return mst, total_weight

# Usage examples
graph = Graph(directed=False)
edges = [(0, 1, 4), (0, 7, 8), (1, 2, 8), (1, 7, 11), (2, 3, 7), 
         (2, 8, 2), (2, 5, 4), (3, 4, 9), (3, 5, 14), (4, 5, 10),
         (5, 6, 2), (6, 7, 1), (6, 8, 6), (7, 8, 7)]

for u, v, w in edges:
    graph.add_edge(u, v, w)

print("BFS from 0:", graph.bfs(0))
print("DFS from 0:", graph.dfs(0))
print("Shortest path 0->4:", graph.shortest_path_dijkstra(0, 4))
print("Has cycle:", graph.detect_cycle())
mst, weight = graph.minimum_spanning_tree_kruskal()
print(f"MST weight: {weight}, edges: {mst}")
```

## ğŸ“š Learning Resources & Practice

### Essential Online Judges

| Platform | Focus | Difficulty | Best For |
|----------|-------|------------|----------|
| **LeetCode** | Interview prep, algorithms | Easy-Hard | FAANG interviews |
| **HackerRank** | Broad programming challenges | Easy-Expert | Skill assessment |
| **CodeForces** | Competitive programming | Div2-Div1 | Contest training |
| **AtCoder** | Mathematical problems | Beginner-Expert | Algorithm analysis |
| **SPOJ** | Classical problems | Varied | Foundation building |
| **Topcoder** | Algorithm competitions | Easy-Hard | Advanced techniques |
| **GeeksforGeeks** | Interview questions | Easy-Hard | Concept learning |
| **InterviewBit** | Structured learning | Easy-Hard | Systematic prep |

### Must-Read Books

**Fundamental Algorithms:**

- **Introduction to Algorithms (CLRS)** - Comprehensive theoretical foundation
- **Algorithm Design Manual (Skiena)** - Practical problem-solving approach
- **Algorithms (Sedgewick & Wayne)** - Clear explanations with Java examples

**Interview Preparation:**

- **Cracking the Coding Interview (McDowell)** - Essential for tech interviews
- **Elements of Programming Interviews** - Language-specific versions available
- **Programming Pearls (Bentley)** - Problem-solving methodology

**Advanced Topics:**

- **Competitive Programming (Halim)** - Contest-level algorithms
- **The Art of Computer Programming (Knuth)** - Mathematical depth

### Problem Categories by Frequency

**High Frequency (Practice First):**

1. **Array & String Manipulation** (35% of interviews)
   - Two pointers, sliding window, hash tables
   - Examples: Two Sum, Longest Substring, Valid Parentheses

2. **Linked List Operations** (20% of interviews)
   - Reversal, cycle detection, merging
   - Examples: Reverse List, Merge Two Lists, Remove Nth Node

3. **Tree Traversals & Manipulation** (25% of interviews)
   - DFS, BFS, path problems, construction
   - Examples: Inorder Traversal, Max Depth, Path Sum

**Medium Frequency:**
4. **Graph Algorithms** (10% of interviews)

- BFS/DFS applications, shortest path
- Examples: Number of Islands, Course Schedule

5. **Dynamic Programming** (8% of interviews)
   - Classic problems, optimization
   - Examples: Fibonacci, Knapsack, Edit Distance

**Lower Frequency but Important:**
6. **Sorting & Searching** (2% of interviews)

- Binary search variations, custom sorting
- Examples: Search in Rotated Array, Merge Intervals

### 12-Week Study Plan

| Week | Focus | Topics | Practice Problems |
|------|-------|--------|------------------|
| **1-2** | Arrays & Strings | Two pointers, sliding window | Two Sum, Longest Substring, Valid Anagram |
| **3-4** | Linked Lists | Manipulation, cycle detection | Reverse List, Merge Lists, Detect Cycle |
| **5-6** | Stacks & Queues | LIFO/FIFO operations | Valid Parentheses, Min Stack, Queue with Stacks |
| **7-8** | Trees & BSTs | Traversals, construction | Inorder Traversal, Validate BST, Path Sum |
| **9-10** | Graphs | BFS, DFS, shortest path | Number of Islands, Course Schedule, Clone Graph |
| **11** | Dynamic Programming | Basic patterns | Climbing Stairs, House Robber, Coin Change |
| **12** | Review & Mock Interviews | Mixed problems | Random hard problems, timed practice |

### Practice Strategy

!!! tip "Daily Practice Routine"

    - **Warm-up**: 1 easy problem (10-15 min)
    - **Main**: 1-2 medium problems (30-45 min each)
    - **Challenge**: 1 hard problem (weekly)
    - **Review**: Revisit problems from 1 week ago

!!! note "Problem-Solving Framework"

    1. **Understand**: Read problem carefully, identify constraints
    2. **Plan**: Think of approach, consider edge cases
    3. **Code**: Implement solution step by step
    4. **Test**: Verify with examples, consider edge cases
    5. **Optimize**: Analyze time/space complexity, improve if possible
    6. **Reflect**: Note patterns and techniques used

### Time Complexity Goals

| Problem Type | Target Time | Complexity Analysis |
|--------------|-------------|-------------------|
| Easy Array/String | 10-15 minutes | O(n) time, O(1) space preferred |
| Medium Trees/Graphs | 20-30 minutes | O(n) or O(n log n) acceptable |
| Hard DP/Backtracking | 30-45 minutes | Focus on correctness first |

---

**Master algorithms, ace interviews, build amazing systems! ğŸš€ğŸ’»**
